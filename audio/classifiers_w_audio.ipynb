{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with text and audio features\n",
    "Updates: \n",
    "* 03/11 - reorganize the code and rename some variables, \n",
    "  change `X` to `x_text`, `X_train` to `x_txt_train`, `X_test` to `x_txt_test`, `Y` to `y_text`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import pickle\n",
    "\n",
    "## ref: https://data-flair.training/blogs/python-mini-project-speech-emotion-recognition/\n",
    "#DataFlair - Extract features (mfcc, chroma, mel) from a sound file\n",
    "def extract_feature(file_name, is_mfcc, is_chroma, is_mel):\n",
    "    \n",
    "    X, sample_rate = librosa.load(file_name, sr=None, mono=True)\n",
    "    \n",
    "    if is_chroma:\n",
    "        stft=np.abs(librosa.stft(X))\n",
    "    result=np.array([])\n",
    "    if is_mfcc:\n",
    "        mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "        result=np.hstack((result, mfccs))\n",
    "    if is_chroma:\n",
    "        chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "        result=np.hstack((result, chroma))\n",
    "    if is_mel:\n",
    "        mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "        result=np.hstack((result, mel))\n",
    "    return result\n",
    "\n",
    "\n",
    "#DataFlair - Load the data and extract features for each sound file\n",
    "def load_data(test_size=0.2):\n",
    "    x = []\n",
    "    audio_list = sorted(os.listdir(train_dir))\n",
    "    # gen = (x for x in audio_list)\n",
    "    \n",
    "    gen = (u for u in train_df[['Dialogue_ID', 'Utterance_ID']].values)\n",
    "    for dia_utt in gen:\n",
    "        dia_id = dia_utt[0]\n",
    "        utt_id = dia_utt[1]\n",
    "        file_name = f\"dia{dia_id}_utt{utt_id}.wav\"\n",
    "        \n",
    "        feature=extract_feature(train_dir + file_name, is_mfcc=True, is_chroma=True, is_mel=True)\n",
    "        x.append(feature)\n",
    "    \n",
    "    labels_1d = np.reshape(labels_matrix, max_dia * max_utt)\n",
    "    labels_1d = labels_1d[~np.equal(labels_1d, 99)]\n",
    "    y = list(labels_1d)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "# for file_name in gen:\n",
    "#     # file_name=os.path.basename(file) ## in the form of dia*_utt*.wav\n",
    "#     print(file_name)\n",
    "#     ## get ids for dialogue \n",
    "#     temp = file_name.split(\"_\")\n",
    "#     dia_id = int(temp[0][3:])\n",
    "#     utt_id = int(temp[1].split(\".\")[0][3:])\n",
    "\n",
    "#     # emotion=labels_matrix[dia_id, utt_id]\n",
    "#     # if emotion not in emotions:\n",
    "#     #     continue\n",
    "#     feature=extract_feature(train_dir + file_name, is_mfcc=True, is_chroma=True, is_mel=True)\n",
    "#     x_matrix[dia_id, utt_id] = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dia = 1039\n",
    "max_utt = 24\n",
    "is_reload = False ## please set it to False if you are using features saved in pickle file \n",
    "test_size = 0.25\n",
    "total = 9988"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract audio features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"../data/train/\"\n",
    "emotions = ['neutral', 'surprise', 'fear', 'sadness', 'joy', 'disgust', 'anger']\n",
    "emo2int = dict(zip(emotions, range(len(emotions))))\n",
    "emo2int['empty'] = 99\n",
    "\n",
    "train_df = pd.read_csv(\"../data/train_sent_emo.csv\")\n",
    "## dia125_utt_3 not working\n",
    "remove_index = train_df[(train_df['Dialogue_ID'] == 125) & (train_df['Utterance_ID'] == 3)].index\n",
    "train_df = train_df.drop(index=remove_index)\n",
    "\n",
    "label_pivot = pd.pivot(data=train_df, columns=\"Utterance_ID\", index=\"Dialogue_ID\", values=\"Emotion\").fillna(\"empty\")\n",
    "label_pivot.loc[60] = [\"empty\"] * label_pivot.shape[1] ## for some reasons, there is no dialogue 60.\n",
    "label_pivot = label_pivot.sort_index()\n",
    "label_pivot = label_pivot.applymap(lambda x: emo2int[x])\n",
    "labels_matrix = label_pivot.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr No.</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>1225</td>\n",
       "      <td>Hey, if mommy can have a wife, daddy can have ...</td>\n",
       "      <td>Ross</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>00:02:35,613</td>\n",
       "      <td>00:02:38,323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>1226</td>\n",
       "      <td>Ohh, its time to go.</td>\n",
       "      <td>Emily</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>00:02:40,869</td>\n",
       "      <td>00:02:42,119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>1228</td>\n",
       "      <td>Huh, what can we do in 17 minutes?</td>\n",
       "      <td>Ross</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>00:02:48,209</td>\n",
       "      <td>00:02:51,295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sr No.                                          Utterance Speaker  \\\n",
       "1163    1225  Hey, if mommy can have a wife, daddy can have ...    Ross   \n",
       "1164    1226                              Ohh, its time to go.   Emily   \n",
       "1166    1228                 Huh, what can we do in 17 minutes?    Ross   \n",
       "\n",
       "      Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode  \\\n",
       "1163  neutral   neutral          125             1       4       18   \n",
       "1164  neutral   neutral          125             2       4       18   \n",
       "1166  neutral   neutral          125             4       4       18   \n",
       "\n",
       "         StartTime       EndTime  \n",
       "1163  00:02:35,613  00:02:38,323  \n",
       "1164  00:02:40,869  00:02:42,119  \n",
       "1166  00:02:48,209  00:02:51,295  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[1163:1166]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFlair - Split the dataset\n",
    "\n",
    "if is_reload:\n",
    "    x_audio, y = load_data(test_size=test_size)\n",
    "\n",
    "    with open(\"../data/train_audio.pickle\", 'wb') as pickle_out:\n",
    "        pickle.dump(x, pickle_out)\n",
    "    with open(\"../data/train_labels.pickle\", 'wb') as pickle_out:\n",
    "        pickle.dump(y, pickle_out)\n",
    "else:\n",
    "    with open(\"../data/train_audio.pickle\", 'rb') as pickle_in:\n",
    "        x_audio = pickle.load(pickle_in)\n",
    "    with open(\"../data/train_labels.pickle\", 'rb') as pickle_in:\n",
    "        y = pickle.load(pickle_in)\n",
    "## x_audio was named as x before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try some classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multi-layer Perceptron with only audio\n",
    "x_au_train,x_test,y_train,y_test = train_test_split(np.array(x_audio), y, test_size=test_size, random_state=9)\n",
    "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
    "model.fit(x_au_train,y_train)\n",
    "y_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.79      0.60      1152\n",
      "           1       0.16      0.04      0.06       308\n",
      "           2       0.18      0.03      0.05        62\n",
      "           3       0.15      0.08      0.10       185\n",
      "           4       0.21      0.15      0.17       439\n",
      "           5       0.01      0.02      0.01        64\n",
      "           6       0.29      0.08      0.12       287\n",
      "\n",
      "    accuracy                           0.41      2497\n",
      "   macro avg       0.21      0.17      0.16      2497\n",
      "weighted avg       0.33      0.41      0.34      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.25      0.08      0.12       257\n",
      "     disgust       0.00      0.00      0.00        65\n",
      "        fear       0.17      0.01      0.03        71\n",
      "         joy       0.23      0.22      0.23       441\n",
      "     neutral       0.51      0.81      0.62      1189\n",
      "     sadness       0.18      0.01      0.02       167\n",
      "    surprise       0.22      0.06      0.09       307\n",
      "\n",
      "    accuracy                           0.44      2497\n",
      "   macro avg       0.22      0.17      0.16      2497\n",
      "weighted avg       0.35      0.44      0.36      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract text features \n",
    "(code from EmotionBaseline.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(element):\n",
    "    final_list = []\n",
    "    \"\"\" Clean up text. Tokenize, lowercase, and remove punctuation and stopwords \"\"\"\n",
    "    #print(\"Running cleaner\")\n",
    "    # Remove punctuation, symbols (#) and stopwords\n",
    "    element = str(element).lower()\n",
    "    new_string = ''\n",
    "    for char in element:\n",
    "        if char not in punctuation_list:\n",
    "            new_string += char\n",
    "    all_wrds = new_string.split(\" \")\n",
    "    for word in all_wrds:\n",
    "        if word not in stop_words_list:\n",
    "            final_list.append(word)\n",
    "    final_string = ' '.join(final_list)\n",
    "    return final_string\n",
    "\n",
    "def tokenize(str_arg):\n",
    "    words = str_arg.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import string\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "stop_words_list = list(spacy.lang.en.STOP_WORDS)\n",
    "punctuation_list = list(string.punctuation)\n",
    "punctuation_list.extend('\\r')\n",
    "punctuation_list.extend('\\n')\n",
    "punctuation_list.extend(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr No.</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "      <th>cleaned_Utterance</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>1225</td>\n",
       "      <td>Hey, if mommy can have a wife, daddy can have ...</td>\n",
       "      <td>Ross</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>00:02:35,613</td>\n",
       "      <td>00:02:38,323</td>\n",
       "      <td>hey mommy wife daddy bra</td>\n",
       "      <td>[hey, mommy, wife, daddy, bra]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>1226</td>\n",
       "      <td>Ohh, its time to go.</td>\n",
       "      <td>Emily</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>00:02:40,869</td>\n",
       "      <td>00:02:42,119</td>\n",
       "      <td>ohh its time</td>\n",
       "      <td>[ohh, its, time]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>1228</td>\n",
       "      <td>Huh, what can we do in 17 minutes?</td>\n",
       "      <td>Ross</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>00:02:48,209</td>\n",
       "      <td>00:02:51,295</td>\n",
       "      <td>huh  minutes</td>\n",
       "      <td>[huh, minutes]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sr No.                                          Utterance Speaker  \\\n",
       "1163    1225  Hey, if mommy can have a wife, daddy can have ...    Ross   \n",
       "1164    1226                              Ohh, its time to go.   Emily   \n",
       "1165    1228                 Huh, what can we do in 17 minutes?    Ross   \n",
       "\n",
       "      Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode  \\\n",
       "1163  neutral   neutral          125             1       4       18   \n",
       "1164  neutral   neutral          125             2       4       18   \n",
       "1165  neutral   neutral          125             4       4       18   \n",
       "\n",
       "         StartTime       EndTime         cleaned_Utterance  \\\n",
       "1163  00:02:35,613  00:02:38,323  hey mommy wife daddy bra   \n",
       "1164  00:02:40,869  00:02:42,119             ohh its time   \n",
       "1165  00:02:48,209  00:02:51,295              huh  minutes   \n",
       "\n",
       "                              tokens  \n",
       "1163  [hey, mommy, wife, daddy, bra]  \n",
       "1164               [ohh, its, time]  \n",
       "1165                  [huh, minutes]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['cleaned_Utterance'] = train_df['Utterance'].apply(cleaning)\n",
    "train_df['tokens'] = train_df['cleaned_Utterance'].apply(tokenize)\n",
    "\n",
    "train_df.index = range(total)\n",
    "train_df.iloc[1163:1166]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_utt = np.reshape(train_df['cleaned_Utterance'].values, (total,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 5, 5, 0, 0, 1, 0, 4]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9978    surprise\n",
       "9979     neutral\n",
       "9980     neutral\n",
       "9981     disgust\n",
       "9982     disgust\n",
       "9983     neutral\n",
       "9984     neutral\n",
       "9985    surprise\n",
       "9986     neutral\n",
       "9987         joy\n",
       "Name: Emotion, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Emotion'][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_text = train_df['cleaned_Utterance'] # it was named as X\n",
    "y_text = train_df['Emotion'] # was named as Y\n",
    "x_txt_train, x_txt_test, y_txt_train, y_txt_test = train_test_split(x_text, y_text, test_size = test_size, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9988]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## IMPORTANT\n",
    "[i for i in range(total + 1) if i not in y_text.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9988"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9988"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_index = [i if i < 1165 else i - 1 for i in x_txt_train.index ]\n",
    "# aud_train = np.array(x)[train_index]\n",
    "# test_index = [i if i < 1165 else i - 1 for i in x_txt_test.index ]\n",
    "# aud_test = np.array(x)[test_index]\n",
    "\n",
    "aud_train = np.array(x_audio)[x_txt_train.index]\n",
    "aud_test = np.array(x_audio)[x_txt_test.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022     neutral\n",
       "9873         joy\n",
       "2542    surprise\n",
       "2034        fear\n",
       "2732        fear\n",
       "8653     neutral\n",
       "7349    surprise\n",
       "1219     neutral\n",
       "6292     neutral\n",
       "4149         joy\n",
       "Name: Emotion, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check whether they are aligned\n",
    "train_df.loc[x_txt_train.index[:10]]['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022     neutral\n",
       "9873         joy\n",
       "2542    surprise\n",
       "2034        fear\n",
       "2732        fear\n",
       "8653     neutral\n",
       "7349    surprise\n",
       "1219     neutral\n",
       "6292     neutral\n",
       "4149         joy\n",
       "Name: Emotion, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_txt_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1160     neutral\n",
       "1161         joy\n",
       "1162         joy\n",
       "1163     neutral\n",
       "1164     neutral\n",
       "1165     neutral\n",
       "1166     neutral\n",
       "1167     neutral\n",
       "1168     neutral\n",
       "1169    surprise\n",
       "Name: Emotion, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[x_text[1160:1170].index]['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1160     neutral\n",
       "1161         joy\n",
       "1162         joy\n",
       "1163     neutral\n",
       "1164     neutral\n",
       "1165     neutral\n",
       "1166     neutral\n",
       "1167     neutral\n",
       "1168     neutral\n",
       "1169    surprise\n",
       "Name: Emotion, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_text[1160:1170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(Y_train),Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "x_txt_train_counts = count_vect.fit_transform(x_txt_train)\n",
    "x_txt_test_counts = count_vect.transform(x_txt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7491, 4657)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_txt_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7491, 180)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aud_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix, hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mix_train = hstack((x_txt_train_counts, aud_train))\n",
    "x_mix_test = hstack((x_txt_test_counts, aud_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.24      0.29      0.26       312\n",
      "     disgust       0.06      0.35      0.10        65\n",
      "        fear       0.02      0.12      0.04        57\n",
      "         joy       0.24      0.17      0.20       422\n",
      "     neutral       0.58      0.22      0.32      1152\n",
      "     sadness       0.11      0.28      0.15       160\n",
      "    surprise       0.21      0.17      0.19       329\n",
      "\n",
      "    accuracy                           0.22      2497\n",
      "   macro avg       0.21      0.23      0.18      2497\n",
      "weighted avg       0.37      0.22      0.25      2497\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "log_clf_wgt = LogisticRegression(class_weight='balanced').fit(x_mix_train, y_txt_train)\n",
    "\n",
    "y_log_pred = log_clf_wgt.predict(x_mix_test)\n",
    "accuracy = accuracy_score(np.array(y_txt_test), y_log_pred)\n",
    "# Combined report with all above metrics\n",
    "print(classification_report(y_txt_test, y_log_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  9.0min\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'penalty' : ['l1', 'l2'],\n",
    "    'class_weight': ['balanced', None],\n",
    "    'C' : [0.5, 0.8, 0.9, 1, 1.2, 1.5, 2, 5],\n",
    "    'solver' : ['liblinear']}\n",
    "\n",
    "# Create grid search object\n",
    "logit = LogisticRegression(random_state=1)\n",
    "log_clf = GridSearchCV(logit, param_grid = param_grid, cv = 5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "grid_cv =log_clf.fit(x_mix_train, y_txt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>81.446990</td>\n",
       "      <td>3.628855</td>\n",
       "      <td>0.007541</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.8</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.8, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>0.444296</td>\n",
       "      <td>0.433244</td>\n",
       "      <td>0.467957</td>\n",
       "      <td>0.464619</td>\n",
       "      <td>0.436582</td>\n",
       "      <td>0.449340</td>\n",
       "      <td>0.014334</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>81.250543</td>\n",
       "      <td>9.968301</td>\n",
       "      <td>0.007801</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.5, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>0.437625</td>\n",
       "      <td>0.434579</td>\n",
       "      <td>0.465955</td>\n",
       "      <td>0.466622</td>\n",
       "      <td>0.439920</td>\n",
       "      <td>0.448940</td>\n",
       "      <td>0.014267</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>88.448559</td>\n",
       "      <td>6.195756</td>\n",
       "      <td>0.007936</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>1.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1.5, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>0.440294</td>\n",
       "      <td>0.434579</td>\n",
       "      <td>0.467290</td>\n",
       "      <td>0.470628</td>\n",
       "      <td>0.431242</td>\n",
       "      <td>0.448806</td>\n",
       "      <td>0.016740</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>91.805664</td>\n",
       "      <td>4.789013</td>\n",
       "      <td>0.007925</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>2</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 2, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>0.443629</td>\n",
       "      <td>0.433244</td>\n",
       "      <td>0.465955</td>\n",
       "      <td>0.462617</td>\n",
       "      <td>0.438585</td>\n",
       "      <td>0.448806</td>\n",
       "      <td>0.013102</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>92.299109</td>\n",
       "      <td>5.399100</td>\n",
       "      <td>0.010307</td>\n",
       "      <td>0.003052</td>\n",
       "      <td>5</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 5, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>0.453636</td>\n",
       "      <td>0.431909</td>\n",
       "      <td>0.460614</td>\n",
       "      <td>0.463284</td>\n",
       "      <td>0.425901</td>\n",
       "      <td>0.447069</td>\n",
       "      <td>0.015280</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84.796355</td>\n",
       "      <td>5.992745</td>\n",
       "      <td>0.008728</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>0.436291</td>\n",
       "      <td>0.438585</td>\n",
       "      <td>0.460614</td>\n",
       "      <td>0.463284</td>\n",
       "      <td>0.435247</td>\n",
       "      <td>0.446804</td>\n",
       "      <td>0.012442</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "7       81.446990      3.628855         0.007541        0.000185     0.8   \n",
       "5       81.250543      9.968301         0.007801        0.000301     0.5   \n",
       "11      88.448559      6.195756         0.007936        0.000492     1.5   \n",
       "13      91.805664      4.789013         0.007925        0.000731       2   \n",
       "15      92.299109      5.399100         0.010307        0.003052       5   \n",
       "9       84.796355      5.992745         0.008728        0.001714       1   \n",
       "\n",
       "   param_penalty param_solver  \\\n",
       "7             l2    liblinear   \n",
       "5             l2    liblinear   \n",
       "11            l2    liblinear   \n",
       "13            l2    liblinear   \n",
       "15            l2    liblinear   \n",
       "9             l2    liblinear   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "7   {'C': 0.8, 'penalty': 'l2', 'solver': 'libline...           0.444296   \n",
       "5   {'C': 0.5, 'penalty': 'l2', 'solver': 'libline...           0.437625   \n",
       "11  {'C': 1.5, 'penalty': 'l2', 'solver': 'libline...           0.440294   \n",
       "13   {'C': 2, 'penalty': 'l2', 'solver': 'liblinear'}           0.443629   \n",
       "15   {'C': 5, 'penalty': 'l2', 'solver': 'liblinear'}           0.453636   \n",
       "9    {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}           0.436291   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "7            0.433244           0.467957           0.464619   \n",
       "5            0.434579           0.465955           0.466622   \n",
       "11           0.434579           0.467290           0.470628   \n",
       "13           0.433244           0.465955           0.462617   \n",
       "15           0.431909           0.460614           0.463284   \n",
       "9            0.438585           0.460614           0.463284   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "7            0.436582         0.449340        0.014334                1  \n",
       "5            0.439920         0.448940        0.014267                2  \n",
       "11           0.431242         0.448806        0.016740                3  \n",
       "13           0.438585         0.448806        0.013102                4  \n",
       "15           0.425901         0.447069        0.015280                5  \n",
       "9            0.435247         0.446804        0.012442                6  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_cv.cv_results_).sort_values(['rank_test_score']).head(6)\n",
    "# best score may lie between C=[0.1, 10], l1 or l2, need deeper search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "best_logit = LogisticRegression(random_state=1, **grid_cv.best_params_)\n",
    "best_logit.fit(x_mix_train, y_txt_train)\n",
    "best_logit_unwgt = best_logit.predict(x_mix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.39      0.18      0.25       312\n",
      "     disgust       0.20      0.02      0.03        65\n",
      "        fear       0.18      0.04      0.06        57\n",
      "         joy       0.43      0.23      0.30       422\n",
      "     neutral       0.53      0.89      0.66      1152\n",
      "     sadness       0.29      0.09      0.13       160\n",
      "    surprise       0.53      0.22      0.32       329\n",
      "\n",
      "    accuracy                           0.51      2497\n",
      "   macro avg       0.36      0.24      0.25      2497\n",
      "weighted avg       0.46      0.51      0.44      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_txt_test, best_logit_unwgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.33      0.43       453\n",
      "           1       0.30      0.54      0.38       133\n",
      "           2       0.07      0.24      0.11        21\n",
      "           3       0.17      0.20      0.19        71\n",
      "           4       0.39      0.40      0.40       177\n",
      "           5       0.07      0.16      0.10        25\n",
      "           6       0.20      0.23      0.22       119\n",
      "\n",
      "    accuracy                           0.34       999\n",
      "   macro avg       0.26      0.30      0.26       999\n",
      "weighted avg       0.43      0.34      0.36       999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
    "model2.fit(x_txt_train_mix, Y_train)\n",
    "y_pred=model2.predict(x_txt_test_mix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.45      0.49       453\n",
      "           1       0.32      0.37      0.34       133\n",
      "           2       0.04      0.05      0.04        21\n",
      "           3       0.14      0.07      0.09        71\n",
      "           4       0.25      0.45      0.32       177\n",
      "           5       0.08      0.04      0.05        25\n",
      "           6       0.18      0.13      0.15       119\n",
      "\n",
      "    accuracy                           0.35       999\n",
      "   macro avg       0.22      0.22      0.21       999\n",
      "weighted avg       0.37      0.35      0.35       999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.20      0.29      1152\n",
      "           1       0.13      0.12      0.12       308\n",
      "           2       0.04      0.18      0.07        62\n",
      "           3       0.11      0.25      0.15       185\n",
      "           4       0.26      0.20      0.23       439\n",
      "           5       0.04      0.27      0.07        64\n",
      "           6       0.24      0.31      0.27       287\n",
      "\n",
      "    accuracy                           0.21      2497\n",
      "   macro avg       0.20      0.22      0.17      2497\n",
      "weighted avg       0.35      0.21      0.24      2497\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "## using logistic on only audio data\n",
    "log_clf_wgt2 = LogisticRegression(class_weight='balanced').fit(x_train, y_train)\n",
    "y_pred_log2 = log_clf_wgt2.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_log2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 44100\n",
    "this_audio = train_dir + \"dia39_utt16.wav\"\n",
    "X, sr = librosa.load(this_audio, sr=None, mono=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025, 833)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stft=np.abs(librosa.stft(X))\n",
    "stft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=np.array([])\n",
    "mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sr, n_mfcc=40).T, axis=0)\n",
    "result=np.hstack((result, mfccs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.94078094e+02,  1.51657318e+02, -4.14482651e+01,  2.59117031e+01,\n",
       "       -8.75755024e+00,  2.62155819e+00, -4.86191893e+00, -8.85141563e+00,\n",
       "       -9.75941467e+00, -1.21939325e+01, -2.22415042e+00, -8.52670097e+00,\n",
       "       -1.23549366e+00, -2.79660892e+00, -6.26574087e+00, -5.61332989e+00,\n",
       "       -1.69966245e+00, -1.18460156e-01, -2.08086920e+00, -5.79642153e+00,\n",
       "       -3.50224090e+00, -2.35849309e+00, -6.33444977e+00, -3.68302155e+00,\n",
       "       -5.60636091e+00, -3.49944377e+00, -3.04542398e+00, -3.83739233e+00,\n",
       "       -3.71297669e+00, -4.36629868e+00, -2.66134501e+00, -3.97081304e+00,\n",
       "       -4.73430920e+00, -2.78555274e+00, -1.85783577e+00, -4.56342030e+00,\n",
       "       -2.49786067e+00, -2.68240547e+00, -2.62995005e+00, -5.55917621e-02])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
