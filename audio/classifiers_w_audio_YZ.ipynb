{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with text and audio features\n",
    "Updates: \n",
    "* 03/11 - reorganize the code and rename some variables, \n",
    "  change `X` to `x_text`, `X_train` to `x_txt_train`, `X_test` to `x_txt_test`, `Y` to `y_text`\n",
    "* 03/18 - try NN\n",
    "  see the 2 code blocks under the section \"convert features and labels\" if you're trying to get x and y for NN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zyixian/anaconda3/envs/speech_gen/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     active environment : /home/zyixian/anaconda3/envs/speech_gen\n",
      "    active env location : /home/zyixian/anaconda3/envs/speech_gen\n",
      "            shell level : 1\n",
      "       user config file : /home/zyixian/.condarc\n",
      " populated config files : \n",
      "          conda version : 4.7.10\n",
      "    conda-build version : 3.18.8\n",
      "         python version : 3.7.3.final.0\n",
      "       virtual packages : \n",
      "       base environment : /sw/arcts/centos7/python3.7-anaconda/2019.07  (read only)\n",
      "           channel URLs : https://repo.anaconda.com/pkgs/main/linux-64\n",
      "                          https://repo.anaconda.com/pkgs/main/noarch\n",
      "                          https://repo.anaconda.com/pkgs/r/linux-64\n",
      "                          https://repo.anaconda.com/pkgs/r/noarch\n",
      "          package cache : /sw/arcts/centos7/python3.7-anaconda/2019.07/pkgs\n",
      "                          /home/zyixian/.conda/pkgs\n",
      "       envs directories : /home/zyixian/.conda/envs\n",
      "                          /sw/arcts/centos7/python3.7-anaconda/2019.07/envs\n",
      "               platform : linux-64\n",
      "             user-agent : conda/4.7.10 requests/2.22.0 CPython/3.7.3 Linux/3.10.0-1062.9.1.el7.x86_64 centos/7.7.1908 glibc/2.17\n",
      "                UID:GID : 114171000:114171000\n",
      "             netrc file : None\n",
      "           offline mode : False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "import string\n",
    "\n",
    "\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import pickle\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler, EditedNearestNeighbours\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "## ref: https://data-flair.training/blogs/python-mini-project-speech-emotion-recognition/\n",
    "#DataFlair - Extract features (mfcc, chroma, mel) from a sound file\n",
    "def extract_feature(file_name, is_mfcc, is_chroma, is_mel):\n",
    "    \n",
    "    X, sample_rate = librosa.load(file_name, sr=None, mono=True)\n",
    "    \n",
    "    if is_chroma:\n",
    "        stft=np.abs(librosa.stft(X))\n",
    "    result=np.array([])\n",
    "    if is_mfcc:\n",
    "        mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "        result=np.hstack((result, mfccs))\n",
    "    if is_chroma:\n",
    "        chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "        result=np.hstack((result, chroma))\n",
    "    if is_mel:\n",
    "        mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "        result=np.hstack((result, mel))\n",
    "    return result\n",
    "\n",
    "\n",
    "#DataFlair - Load the data and extract features for each sound file\n",
    "def load_data(test_size=0.2, is_mfcc=True, is_chroma=True, is_mel=True):\n",
    "    x = []\n",
    "    audio_list = sorted(os.listdir(train_dir))\n",
    "    # gen = (x for x in audio_list)\n",
    "    \n",
    "    gen = (u for u in train_df[['Dialogue_ID', 'Utterance_ID']].values)\n",
    "    for dia_utt in gen:\n",
    "        dia_id = dia_utt[0]\n",
    "        utt_id = dia_utt[1]\n",
    "        file_name = f\"dia{dia_id}_utt{utt_id}.wav\"\n",
    "        \n",
    "        feature=extract_feature(train_dir + file_name, is_mfcc=is_mfcc, is_chroma=is_chroma, is_mel=is_mel)\n",
    "        x.append(feature)\n",
    "    \n",
    "    labels_1d = np.reshape(labels_matrix, max_dia * max_utt)\n",
    "    labels_1d = labels_1d[~np.equal(labels_1d, 99)]\n",
    "    y = list(labels_1d)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "### text feature generation\n",
    "def cleaning(element):\n",
    "    final_list = []\n",
    "    \"\"\" Clean up text. Tokenize, lowercase, and remove punctuation and stopwords \"\"\"\n",
    "    #print(\"Running cleaner\")\n",
    "    # Remove punctuation, symbols (#) and stopwords\n",
    "    element = str(element).lower()\n",
    "    new_string = ''\n",
    "    for char in element:\n",
    "        if char not in punctuation_list:\n",
    "            new_string += char\n",
    "    all_wrds = new_string.split(\" \")\n",
    "    for word in all_wrds:\n",
    "        if word not in stop_words_list:\n",
    "            final_list.append(word)\n",
    "    final_string = ' '.join(final_list)\n",
    "    return final_string\n",
    "\n",
    "def tokenize(str_arg):\n",
    "    words = str_arg.split()\n",
    "    return words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dia = 1039\n",
    "max_utt = 24\n",
    "is_reload = False ## please set it to False if you are using features saved in pickle file \n",
    "test_size = 0.25\n",
    "total = 9988"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"../data/train/\"\n",
    "emotions = ['neutral', 'surprise', 'fear', 'sadness', 'joy', 'disgust', 'anger']\n",
    "emo2int = dict(zip(emotions, range(len(emotions))))\n",
    "emo2int['empty'] = 99\n",
    "int2emo = {v: k for k,v in emo2int.items()}\n",
    "sentiments = ['negative', 'neutral', 'positive']\n",
    "sent2int = {\n",
    "    'negative': 0,\n",
    "    'neutral': 1,\n",
    "    'positive': 2\n",
    "}\n",
    "int2sent = {v: k for k, v in sent2int.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract audio features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/train_sent_emo.csv\")\n",
    "## dia125_utt_3 not working\n",
    "remove_index = train_df[(train_df['Dialogue_ID'] == 125) & (train_df['Utterance_ID'] == 3)].index\n",
    "train_df = train_df.drop(index=remove_index)\n",
    "\n",
    "label_pivot = pd.pivot(data=train_df, columns=\"Utterance_ID\", index=\"Dialogue_ID\", values=\"Emotion\").fillna(\"empty\")\n",
    "label_pivot.loc[60] = [\"empty\"] * label_pivot.shape[1] ## for some reasons, there is no dialogue 60.\n",
    "label_pivot = label_pivot.sort_index()\n",
    "label_pivot = label_pivot.applymap(lambda x: emo2int[x])\n",
    "labels_matrix = label_pivot.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['sentiment_int'] = train_df['Sentiment'].apply(lambda x: sent2int[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr No.</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "      <th>sentiment_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>1225</td>\n",
       "      <td>Hey, if mommy can have a wife, daddy can have ...</td>\n",
       "      <td>Ross</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>00:02:35,613</td>\n",
       "      <td>00:02:38,323</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>1226</td>\n",
       "      <td>Ohh, its time to go.</td>\n",
       "      <td>Emily</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>00:02:40,869</td>\n",
       "      <td>00:02:42,119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>1228</td>\n",
       "      <td>Huh, what can we do in 17 minutes?</td>\n",
       "      <td>Ross</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>00:02:48,209</td>\n",
       "      <td>00:02:51,295</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sr No.                                          Utterance Speaker  \\\n",
       "1163    1225  Hey, if mommy can have a wife, daddy can have ...    Ross   \n",
       "1164    1226                              Ohh, its time to go.   Emily   \n",
       "1166    1228                 Huh, what can we do in 17 minutes?    Ross   \n",
       "\n",
       "      Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode  \\\n",
       "1163  neutral   neutral          125             1       4       18   \n",
       "1164  neutral   neutral          125             2       4       18   \n",
       "1166  neutral   neutral          125             4       4       18   \n",
       "\n",
       "         StartTime       EndTime  sentiment_int  \n",
       "1163  00:02:35,613  00:02:38,323              1  \n",
       "1164  00:02:40,869  00:02:42,119              1  \n",
       "1166  00:02:48,209  00:02:51,295              1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[1163:1166]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFlair - Split the dataset\n",
    "if is_reload:\n",
    "    x_audio, y = load_data(test_size=test_size)\n",
    "    with open(\"../data/train_audio_nomel.pickle\", 'wb') as pickle_out:\n",
    "        pickle.dump(x_audio, pickle_out)\n",
    "    with open(\"../data/train_labels_nomel.pickle\", 'wb') as pickle_out:\n",
    "        pickle.dump(y, pickle_out)\n",
    "else:\n",
    "    with open(\"../data/train_audio.pickle\", 'rb') as pickle_in:\n",
    "        x_audio = pickle.load(pickle_in)\n",
    "    with open(\"../data/train_labels.pickle\", 'rb') as pickle_in:\n",
    "        y = pickle.load(pickle_in)\n",
    "## x_audio was named as x before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try some classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Multi-layer Perceptron with only audio\n",
    "# x_au_train,x_test,y_train,y_test = train_test_split(np.array(x_audio), y, test_size=test_size, random_state=9)\n",
    "# model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
    "# model.fit(x_au_train,y_train)\n",
    "# y_pred=model.predict(x_test)\n",
    "\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract text features \n",
    "(code from EmotionBaseline.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /home/zyixian/anaconda3/envs/speech_gen/lib/python3.8/site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /home/zyixian/anaconda3/envs/speech_gen/lib/python3.8/site-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/zyixian/anaconda3/envs/speech_gen/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/zyixian/anaconda3/envs/speech_gen/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: thinc==7.4.0 in /home/zyixian/anaconda3/envs/speech_gen/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/zyixian/anaconda3/envs/speech_gen/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/zyixian/anaconda3/envs/speech_gen/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/zyixian/anaconda3/envs/speech_gen/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/zyixian/anaconda3/envs/speech_gen/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/zyixian/anaconda3/envs/speech_gen/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/zyixian/anaconda3/envs/speech_gen/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.43.0)\n",
      "Requirement already satisfied: setuptools in /home/zyixian/anaconda3/envs/speech_gen/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (45.2.0.post20200209)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/zyixian/anaconda3/envs/speech_gen/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/zyixian/anaconda3/envs/speech_gen/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/zyixian/anaconda3/envs/speech_gen/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/zyixian/anaconda3/envs/speech_gen/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/zyixian/anaconda3/envs/speech_gen/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zyixian/anaconda3/envs/speech_gen/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.11.28)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/zyixian/anaconda3/envs/speech_gen/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/home/zyixian/anaconda3/envs/speech_gen/lib/python3.8/site-packages/en_core_web_sm\n",
      "-->\n",
      "/home/zyixian/anaconda3/envs/speech_gen/lib/python3.8/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "# !python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "stop_words_list = list(spacy.lang.en.STOP_WORDS)\n",
    "punctuation_list = list(string.punctuation)\n",
    "punctuation_list.extend('\\r')\n",
    "punctuation_list.extend('\\n')\n",
    "punctuation_list.extend(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr No.</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "      <th>sentiment_int</th>\n",
       "      <th>cleaned_Utterance</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>1225</td>\n",
       "      <td>Hey, if mommy can have a wife, daddy can have ...</td>\n",
       "      <td>Ross</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>00:02:35,613</td>\n",
       "      <td>00:02:38,323</td>\n",
       "      <td>1</td>\n",
       "      <td>hey mommy wife daddy bra</td>\n",
       "      <td>[hey, mommy, wife, daddy, bra]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>1226</td>\n",
       "      <td>Ohh, its time to go.</td>\n",
       "      <td>Emily</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>00:02:40,869</td>\n",
       "      <td>00:02:42,119</td>\n",
       "      <td>1</td>\n",
       "      <td>ohh its time</td>\n",
       "      <td>[ohh, its, time]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>1228</td>\n",
       "      <td>Huh, what can we do in 17 minutes?</td>\n",
       "      <td>Ross</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>00:02:48,209</td>\n",
       "      <td>00:02:51,295</td>\n",
       "      <td>1</td>\n",
       "      <td>huh  minutes</td>\n",
       "      <td>[huh, minutes]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sr No.                                          Utterance Speaker  \\\n",
       "1163    1225  Hey, if mommy can have a wife, daddy can have ...    Ross   \n",
       "1164    1226                              Ohh, its time to go.   Emily   \n",
       "1165    1228                 Huh, what can we do in 17 minutes?    Ross   \n",
       "\n",
       "      Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode  \\\n",
       "1163  neutral   neutral          125             1       4       18   \n",
       "1164  neutral   neutral          125             2       4       18   \n",
       "1165  neutral   neutral          125             4       4       18   \n",
       "\n",
       "         StartTime       EndTime  sentiment_int         cleaned_Utterance  \\\n",
       "1163  00:02:35,613  00:02:38,323              1  hey mommy wife daddy bra   \n",
       "1164  00:02:40,869  00:02:42,119              1             ohh its time   \n",
       "1165  00:02:48,209  00:02:51,295              1              huh  minutes   \n",
       "\n",
       "                              tokens  \n",
       "1163  [hey, mommy, wife, daddy, bra]  \n",
       "1164               [ohh, its, time]  \n",
       "1165                  [huh, minutes]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['cleaned_Utterance'] = train_df['Utterance'].apply(cleaning)\n",
    "train_df['tokens'] = train_df['cleaned_Utterance'].apply(tokenize)\n",
    "\n",
    "train_df.index = range(total)\n",
    "train_df.iloc[1163:1166]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_utt = np.reshape(train_df['cleaned_Utterance'].values, (total,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 surprise\n",
      "0 neutral\n",
      "0 neutral\n",
      "5 disgust\n",
      "5 disgust\n",
      "0 neutral\n",
      "0 neutral\n",
      "1 surprise\n",
      "0 neutral\n",
      "4 joy\n"
     ]
    }
   ],
   "source": [
    "for i in range(-10, 0):\n",
    "    print(y[i], train_df['Emotion'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9988]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_text = train_df['cleaned_Utterance'] # it was named as X\n",
    "y_text = train_df['Emotion'] # was named as Y\n",
    "x_txt_train, x_txt_test, y_txt_train, y_txt_test = train_test_split(x_text, y_text, test_size = test_size, random_state = 42)\n",
    "\n",
    "## IMPORTANT there's no index 1165 before, run this to chech if you fixed the indices\n",
    "[i for i in range(total + 1) if i not in y_text.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud_train = np.array(x_audio)[x_txt_train.index]\n",
    "aud_test = np.array(x_audio)[x_txt_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral neutral\n",
      "joy joy\n",
      "surprise surprise\n",
      "fear fear\n",
      "fear fear\n",
      "neutral neutral\n",
      "surprise surprise\n",
      "neutral neutral\n",
      "neutral neutral\n",
      "joy joy\n"
     ]
    }
   ],
   "source": [
    "## check whether they are aligned\n",
    "for i in range(0, 10):\n",
    "    print(y_txt_train[:10].values[i], train_df.loc[x_txt_train.index[:10]]['Emotion'].values[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "x_txt_train_counts = count_vect.fit_transform(x_txt_train)\n",
    "x_txt_test_counts = count_vect.transform(x_txt_test)\n",
    "\n",
    "# x_txt_train_counts.shape #(7491, 4657)\n",
    "\n",
    "# aud_train.shape #(7491, 180)\n",
    "\n",
    "x_mix_train = hstack((x_txt_train_counts, aud_train))\n",
    "x_mix_test = hstack((x_txt_test_counts, aud_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sentiment\n",
    "y_sent_train = train_df['sentiment_int'].values[y_txt_train.index]\n",
    "y_sent_test = train_df['sentiment_int'].values[y_txt_test.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert features and lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y(y_labels, num_class=2):\n",
    "    \"\"\"convert a list of labels to one-hot encoding for neural network\"\"\"\n",
    "    if num_class > 2:\n",
    "        encodings = np.zeros((len(y_labels), num_class))\n",
    "    else:\n",
    "        raise ValueError(\"Number of class should be greater than 2, num_class =\", num_class)\n",
    "    for i, this_y in enumerate(y_labels):\n",
    "        encodings[i, this_y] = 1\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_arr_train = x_mix_train.toarray()\n",
    "x_arr_test = x_mix_test.toarray()\n",
    "\n",
    "y_num_train = np.array(y)[y_txt_train.index] ## number labels for emotions\n",
    "y_num_test = np.array(y)[y_txt_test.index]\n",
    "y_1hot_train = convert_y(y_num_train, 7)\n",
    "y_1hot_test = convert_y(y_num_test, 7)\n",
    "\n",
    "input_shape = x_mix_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.24      0.29      0.26       312\n",
      "     disgust       0.06      0.35      0.10        65\n",
      "        fear       0.02      0.12      0.04        57\n",
      "         joy       0.24      0.17      0.20       422\n",
      "     neutral       0.58      0.22      0.32      1152\n",
      "     sadness       0.11      0.28      0.15       160\n",
      "    surprise       0.21      0.17      0.19       329\n",
      "\n",
      "    accuracy                           0.22      2497\n",
      "   macro avg       0.21      0.23      0.18      2497\n",
      "weighted avg       0.37      0.22      0.25      2497\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zyixian/anaconda3/envs/speech_gen/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log_clf_wgt = LogisticRegression(class_weight='balanced').fit(x_mix_train, y_txt_train)\n",
    "\n",
    "y_log_pred = log_clf_wgt.predict(x_mix_test)\n",
    "accuracy = accuracy_score(np.array(y_txt_test), y_log_pred)\n",
    "# Combined report with all above metrics\n",
    "print(classification_report(y_txt_test, y_log_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 36 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:  8.0min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'penalty' : ['l1', 'l2'],\n",
    "    'class_weight': ['balanced', None],\n",
    "    'C' : [0.5, 0.8, 0.9, 1, 1.2, 1.5, 2, 5],\n",
    "    'solver' : ['liblinear']}\n",
    "\n",
    "# Create grid search object\n",
    "logit = LogisticRegression(random_state=1)\n",
    "log_clf = GridSearchCV(logit, param_grid = param_grid, cv = 5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "grid_cv =log_clf.fit(x_mix_train, y_txt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.8, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_cv.cv_results_).sort_values(['rank_test_score'])\n",
    "results.head(6)\n",
    "# best score may lie between C=[0.1, 10], l1 or l2, need deeper search\n",
    "best_wgt_params = results[results['param_class_weight'] == \"balanced\"].head(1)['params'].values[0]\n",
    "best_wgt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.26      0.20      0.22       312\n",
      "     disgust       0.14      0.18      0.16        65\n",
      "        fear       0.08      0.14      0.10        57\n",
      "         joy       0.39      0.35      0.37       422\n",
      "     neutral       0.57      0.63      0.60      1152\n",
      "     sadness       0.18      0.18      0.18       160\n",
      "    surprise       0.42      0.35      0.38       329\n",
      "\n",
      "    accuracy                           0.44      2497\n",
      "   macro avg       0.29      0.29      0.29      2497\n",
      "weighted avg       0.43      0.44      0.43      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_wgt_params = {'C': 0.8, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}\n",
    "base_logit_wgt = LogisticRegression(random_state=1, **best_wgt_params)\n",
    "base_logit_wgt.fit(x_txt_train_counts, y_txt_train)\n",
    "base_logit_wgt_pred = base_logit_wgt.predict(x_txt_test_counts)\n",
    "print(classification_report(y_txt_test, base_logit_wgt_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_wgt_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c724fe5cf797>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_logit_wgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mbest_wgt_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_logit_wgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mix_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_txt_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_logit_wgt_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_logit_wgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mix_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_txt_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_logit_wgt_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_wgt_params' is not defined"
     ]
    }
   ],
   "source": [
    "best_logit_wgt = LogisticRegression(random_state=1, **best_wgt_params)\n",
    "best_logit_wgt.fit(x_mix_train, y_txt_train)\n",
    "best_logit_wgt_pred = best_logit_wgt.predict(x_mix_test)\n",
    "print(classification_report(y_txt_test, best_logit_wgt_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-73d92a36f176>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_logit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgrid_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_logit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mix_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_txt_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_logit_unwgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_logit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mix_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbest_logit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_cv' is not defined"
     ]
    }
   ],
   "source": [
    "best_logit = LogisticRegression(random_state=1, **grid_cv.best_params_)\n",
    "best_logit.fit(x_mix_train, y_txt_train)\n",
    "best_logit_unwgt = best_logit.predict(x_mix_test)\n",
    "best_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.37      0.14      0.20       312\n",
      "     disgust       0.50      0.02      0.03        65\n",
      "        fear       0.17      0.02      0.03        57\n",
      "         joy       0.46      0.21      0.29       422\n",
      "     neutral       0.52      0.92      0.66      1152\n",
      "     sadness       0.32      0.07      0.12       160\n",
      "    surprise       0.65      0.19      0.29       329\n",
      "\n",
      "    accuracy                           0.51      2497\n",
      "   macro avg       0.43      0.22      0.23      2497\n",
      "weighted avg       0.49      0.51      0.43      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_txt_test, best_logit_unwgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'neutral', 'neutral', ..., 'neutral', 'neutral',\n",
       "       'neutral'], dtype=object)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_logit_wgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.37      0.14      0.20       312\n",
      "     disgust       0.50      0.02      0.03        65\n",
      "        fear       0.17      0.02      0.03        57\n",
      "         joy       0.46      0.21      0.29       422\n",
      "     neutral       0.52      0.92      0.66      1152\n",
      "     sadness       0.32      0.07      0.12       160\n",
      "    surprise       0.65      0.19      0.29       329\n",
      "\n",
      "    accuracy                           0.51      2497\n",
      "   macro avg       0.43      0.22      0.23      2497\n",
      "weighted avg       0.49      0.51      0.43      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_txt_test, best_logit_unwgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.39      0.18      0.25       312\n",
      "     disgust       0.20      0.02      0.03        65\n",
      "        fear       0.18      0.04      0.06        57\n",
      "         joy       0.43      0.23      0.30       422\n",
      "     neutral       0.53      0.89      0.66      1152\n",
      "     sadness       0.29      0.09      0.13       160\n",
      "    surprise       0.53      0.22      0.32       329\n",
      "\n",
      "    accuracy                           0.51      2497\n",
      "   macro avg       0.36      0.24      0.25      2497\n",
      "weighted avg       0.46      0.51      0.44      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_txt_test, best_logit_unwgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.33      0.43       453\n",
      "           1       0.30      0.54      0.38       133\n",
      "           2       0.07      0.24      0.11        21\n",
      "           3       0.17      0.20      0.19        71\n",
      "           4       0.39      0.40      0.40       177\n",
      "           5       0.07      0.16      0.10        25\n",
      "           6       0.20      0.23      0.22       119\n",
      "\n",
      "    accuracy                           0.34       999\n",
      "   macro avg       0.26      0.30      0.26       999\n",
      "weighted avg       0.43      0.34      0.36       999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
    "model2.fit(x_txt_train_mix, Y_train)\n",
    "y_pred=model2.predict(x_txt_test_mix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.45      0.49       453\n",
      "           1       0.32      0.37      0.34       133\n",
      "           2       0.04      0.05      0.04        21\n",
      "           3       0.14      0.07      0.09        71\n",
      "           4       0.25      0.45      0.32       177\n",
      "           5       0.08      0.04      0.05        25\n",
      "           6       0.18      0.13      0.15       119\n",
      "\n",
      "    accuracy                           0.35       999\n",
      "   macro avg       0.22      0.22      0.21       999\n",
      "weighted avg       0.37      0.35      0.35       999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.20      0.29      1152\n",
      "           1       0.13      0.12      0.12       308\n",
      "           2       0.04      0.18      0.07        62\n",
      "           3       0.11      0.25      0.15       185\n",
      "           4       0.26      0.20      0.23       439\n",
      "           5       0.04      0.27      0.07        64\n",
      "           6       0.24      0.31      0.27       287\n",
      "\n",
      "    accuracy                           0.21      2497\n",
      "   macro avg       0.20      0.22      0.17      2497\n",
      "weighted avg       0.35      0.21      0.24      2497\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "## using logistic on only audio data\n",
    "log_clf_wgt2 = LogisticRegression(class_weight='balanced').fit(x_train, y_train)\n",
    "y_pred_log2 = log_clf_wgt2.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_log2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 44100\n",
    "this_audio = train_dir + \"dia39_utt16.wav\"\n",
    "X, sr = librosa.load(this_audio, sr=None, mono=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025, 833)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stft=np.abs(librosa.stft(X))\n",
    "stft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=np.array([])\n",
    "mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sr, n_mfcc=40).T, axis=0)\n",
    "result=np.hstack((result, mfccs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion classification using a Simple NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_nn = models.Sequential()\n",
    "simple_nn.add(layers.Dense(32, activation='relu', input_shape=(input_shape, )))\n",
    "simple_nn.add(layers.Dense(16, activation='relu'))\n",
    "simple_nn.add(layers.Dense(7, activation='softmax'))\n",
    "simple_nn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 32)                154816    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7)                 119       \n",
      "=================================================================\n",
      "Total params: 155,463\n",
      "Trainable params: 155,463\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        1.74471360e-09, 1.72682491e-09, 1.69412095e-09],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        3.46812584e-07, 3.42379650e-07, 3.40634188e-07],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        1.26655038e-07, 1.24367318e-07, 1.23367855e-07],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        5.23652277e-09, 5.20029309e-09, 5.06713382e-09],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        1.38951861e-09, 1.39165923e-09, 1.40881651e-09],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        8.01268953e-08, 7.71062858e-08, 7.68958301e-08]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mix_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "7491/7491 [==============================] - 1s 159us/step - loss: 0.6053 - accuracy: 0.7975\n",
      "Epoch 2/25\n",
      "7491/7491 [==============================] - 1s 114us/step - loss: 0.5869 - accuracy: 0.8023\n",
      "Epoch 3/25\n",
      "7491/7491 [==============================] - 1s 119us/step - loss: 0.5911 - accuracy: 0.7992\n",
      "Epoch 4/25\n",
      "7491/7491 [==============================] - 1s 119us/step - loss: 0.6449 - accuracy: 0.7817\n",
      "Epoch 5/25\n",
      "7491/7491 [==============================] - 1s 114us/step - loss: 0.6033 - accuracy: 0.7915\n",
      "Epoch 6/25\n",
      "7491/7491 [==============================] - 1s 119us/step - loss: 0.5929 - accuracy: 0.8034\n",
      "Epoch 7/25\n",
      "7491/7491 [==============================] - 1s 132us/step - loss: 0.5959 - accuracy: 0.7987\n",
      "Epoch 8/25\n",
      "7491/7491 [==============================] - 1s 116us/step - loss: 0.5811 - accuracy: 0.8024\n",
      "Epoch 9/25\n",
      "7491/7491 [==============================] - 1s 132us/step - loss: 0.5764 - accuracy: 0.8035\n",
      "Epoch 10/25\n",
      "7491/7491 [==============================] - 1s 132us/step - loss: 0.5587 - accuracy: 0.8116\n",
      "Epoch 11/25\n",
      "7491/7491 [==============================] - 1s 119us/step - loss: 0.5647 - accuracy: 0.8042\n",
      "Epoch 12/25\n",
      "7491/7491 [==============================] - 1s 124us/step - loss: 0.5656 - accuracy: 0.8072\n",
      "Epoch 13/25\n",
      "7491/7491 [==============================] - 1s 129us/step - loss: 0.5499 - accuracy: 0.8150\n",
      "Epoch 14/25\n",
      "7491/7491 [==============================] - 1s 126us/step - loss: 0.5410 - accuracy: 0.8168\n",
      "Epoch 15/25\n",
      "7491/7491 [==============================] - 1s 119us/step - loss: 0.5673 - accuracy: 0.8056\n",
      "Epoch 16/25\n",
      "7491/7491 [==============================] - 1s 119us/step - loss: 0.5548 - accuracy: 0.8106\n",
      "Epoch 17/25\n",
      "7491/7491 [==============================] - 1s 130us/step - loss: 0.5443 - accuracy: 0.8159\n",
      "Epoch 18/25\n",
      "7491/7491 [==============================] - 1s 140us/step - loss: 0.5521 - accuracy: 0.8063\n",
      "Epoch 19/25\n",
      "7491/7491 [==============================] - 1s 127us/step - loss: 0.5505 - accuracy: 0.8108\n",
      "Epoch 20/25\n",
      "7491/7491 [==============================] - 1s 125us/step - loss: 0.5341 - accuracy: 0.8195\n",
      "Epoch 21/25\n",
      "7491/7491 [==============================] - 1s 123us/step - loss: 0.5359 - accuracy: 0.8199\n",
      "Epoch 22/25\n",
      "7491/7491 [==============================] - 1s 138us/step - loss: 0.5245 - accuracy: 0.8217\n",
      "Epoch 23/25\n",
      "7491/7491 [==============================] - 1s 142us/step - loss: 0.5336 - accuracy: 0.8163\n",
      "Epoch 24/25\n",
      "7491/7491 [==============================] - 1s 124us/step - loss: 0.5247 - accuracy: 0.8199\n",
      "Epoch 25/25\n",
      "7491/7491 [==============================] - 1s 145us/step - loss: 0.5173 - accuracy: 0.8221\n"
     ]
    }
   ],
   "source": [
    "history = simple_nn.fit(x_arr_train, y_1hot_train, epochs=25, batch_size=128, verbose=0)\n",
    "y_nn_predict = simple_nn.predict(x_arr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.56      0.63      0.59      1152\n",
      "    surprise       0.39      0.22      0.28       329\n",
      "        fear       0.06      0.04      0.05        57\n",
      "     sadness       0.14      0.11      0.12       160\n",
      "         joy       0.32      0.41      0.36       422\n",
      "     disgust       0.11      0.11      0.11        65\n",
      "       anger       0.29      0.24      0.26       312\n",
      "\n",
      "    accuracy                           0.43      2497\n",
      "   macro avg       0.27      0.25      0.25      2497\n",
      "weighted avg       0.41      0.43      0.42      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_1hot_test, axis=1), np.argmax(y_nn_predict, axis=1), target_names=emotions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 3, ..., 4, 3, 0])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_1hot_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 0, ..., 4, 0, 4])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_nn_predict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(1, 26)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import unit_norm, min_max_norm\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model2 = models.Sequential()\n",
    "nn_model2.add(layers.Dense(32, activation='tanh', input_shape=(input_shape, ), kernel_constraint=min_max_norm(-3, 3), bias_constraint=unit_norm()))\n",
    "nn_model2.add(layers.Dropout(0.2))\n",
    "nn_model2.add(layers.Dense(16, activation='tanh'))\n",
    "nn_model2.add(layers.Dropout(0.2))\n",
    "nn_model2.add(layers.Dense(7, activation='softmax'))\n",
    "nn_model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00002: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_categorical_accuracy', mode='max', verbose=1)\n",
    "\n",
    "history2 = nn_model2.fit(x_arr_train, y_1hot_train, epochs=15, batch_size=128, validation_split=0.15, verbose=0, callbacks=[es]) #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history2.history['loss']\n",
    "val_loss = history2.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history2.history['categorical_accuracy']\n",
    "val_acc = history2.history['val_categorical_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.46      1.00      0.63      1152\n",
      "    surprise       0.00      0.00      0.00       329\n",
      "        fear       0.00      0.00      0.00        57\n",
      "     sadness       0.00      0.00      0.00       160\n",
      "         joy       0.00      0.00      0.00       422\n",
      "     disgust       0.00      0.00      0.00        65\n",
      "       anger       0.00      0.00      0.00       312\n",
      "\n",
      "    accuracy                           0.46      2497\n",
      "   macro avg       0.07      0.14      0.09      2497\n",
      "weighted avg       0.21      0.46      0.29      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn_predict2 = nn_model2.predict(x_arr_test)\n",
    "print(classification_report(np.argmax(y_1hot_test, axis=1), np.argmax(y_nn_predict2, axis=1), target_names=emotions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_sent_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed: 10.1min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'penalty' : ['l1', 'l2'],\n",
    "    'class_weight': ['balanced'], # , None\n",
    "    'C' : [0.1, 0.5, 0.7, 1, 7, 10, 15, 20],\n",
    "    'solver' : ['liblinear']}\n",
    "\n",
    "# Create grid search object\n",
    "logit = LogisticRegression(random_state=1)\n",
    "grid_cv_sent = GridSearchCV(logit, param_grid = param_grid, cv = 4, verbose=2, n_jobs=-1).fit(x_mix_train, y_sent_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.429574</td>\n",
       "      <td>3.716243</td>\n",
       "      <td>0.008193</td>\n",
       "      <td>0.003015</td>\n",
       "      <td>0.5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.5, 'class_weight': 'balanced', 'penalt...</td>\n",
       "      <td>0.510411</td>\n",
       "      <td>0.531767</td>\n",
       "      <td>0.556327</td>\n",
       "      <td>0.532585</td>\n",
       "      <td>0.532773</td>\n",
       "      <td>0.016247</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.079005</td>\n",
       "      <td>2.335466</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>0.004238</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1, 'class_weight': 'balanced', 'penalty'...</td>\n",
       "      <td>0.514148</td>\n",
       "      <td>0.532301</td>\n",
       "      <td>0.560064</td>\n",
       "      <td>0.519765</td>\n",
       "      <td>0.531570</td>\n",
       "      <td>0.017715</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.339657</td>\n",
       "      <td>1.398755</td>\n",
       "      <td>0.005232</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.7</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.7, 'class_weight': 'balanced', 'penalt...</td>\n",
       "      <td>0.514682</td>\n",
       "      <td>0.532835</td>\n",
       "      <td>0.557928</td>\n",
       "      <td>0.518697</td>\n",
       "      <td>0.531036</td>\n",
       "      <td>0.016927</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50.828467</td>\n",
       "      <td>1.226927</td>\n",
       "      <td>0.004471</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10, 'class_weight': 'balanced', 'penalty...</td>\n",
       "      <td>0.515216</td>\n",
       "      <td>0.533369</td>\n",
       "      <td>0.556327</td>\n",
       "      <td>0.518697</td>\n",
       "      <td>0.530902</td>\n",
       "      <td>0.016183</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>51.828973</td>\n",
       "      <td>1.984817</td>\n",
       "      <td>0.004736</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1, 'class_weight': 'balanced', 'penalty'...</td>\n",
       "      <td>0.515216</td>\n",
       "      <td>0.531767</td>\n",
       "      <td>0.553657</td>\n",
       "      <td>0.521368</td>\n",
       "      <td>0.530502</td>\n",
       "      <td>0.014619</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>47.941090</td>\n",
       "      <td>2.707076</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>15</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 15, 'class_weight': 'balanced', 'penalty...</td>\n",
       "      <td>0.516284</td>\n",
       "      <td>0.535505</td>\n",
       "      <td>0.554191</td>\n",
       "      <td>0.516026</td>\n",
       "      <td>0.530501</td>\n",
       "      <td>0.015795</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>54.444333</td>\n",
       "      <td>3.042131</td>\n",
       "      <td>0.005599</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>7</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 7, 'class_weight': 'balanced', 'penalty'...</td>\n",
       "      <td>0.515750</td>\n",
       "      <td>0.528564</td>\n",
       "      <td>0.556327</td>\n",
       "      <td>0.517094</td>\n",
       "      <td>0.529434</td>\n",
       "      <td>0.016306</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.624824</td>\n",
       "      <td>1.828291</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'penalt...</td>\n",
       "      <td>0.507208</td>\n",
       "      <td>0.524826</td>\n",
       "      <td>0.553123</td>\n",
       "      <td>0.532051</td>\n",
       "      <td>0.529302</td>\n",
       "      <td>0.016456</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44.650046</td>\n",
       "      <td>3.442787</td>\n",
       "      <td>0.004812</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.5, 'class_weight': 'balanced', 'penalt...</td>\n",
       "      <td>0.510411</td>\n",
       "      <td>0.532301</td>\n",
       "      <td>0.557395</td>\n",
       "      <td>0.514957</td>\n",
       "      <td>0.528766</td>\n",
       "      <td>0.018437</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>49.786807</td>\n",
       "      <td>4.478527</td>\n",
       "      <td>0.015125</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.7</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.7, 'class_weight': 'balanced', 'penalt...</td>\n",
       "      <td>0.513615</td>\n",
       "      <td>0.532301</td>\n",
       "      <td>0.552589</td>\n",
       "      <td>0.515491</td>\n",
       "      <td>0.528499</td>\n",
       "      <td>0.015697</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "2       13.429574      3.716243         0.008193        0.003015     0.5   \n",
       "6       23.079005      2.335466         0.011178        0.004238       1   \n",
       "4       16.339657      1.398755         0.005232        0.001057     0.7   \n",
       "11      50.828467      1.226927         0.004471        0.000415      10   \n",
       "7       51.828973      1.984817         0.004736        0.000383       1   \n",
       "13      47.941090      2.707076         0.004719        0.000448      15   \n",
       "9       54.444333      3.042131         0.005599        0.001048       7   \n",
       "1       20.624824      1.828291         0.004367        0.000168     0.1   \n",
       "3       44.650046      3.442787         0.004812        0.000486     0.5   \n",
       "5       49.786807      4.478527         0.015125        0.006583     0.7   \n",
       "\n",
       "   param_class_weight param_penalty param_solver  \\\n",
       "2            balanced            l1    liblinear   \n",
       "6            balanced            l1    liblinear   \n",
       "4            balanced            l1    liblinear   \n",
       "11           balanced            l2    liblinear   \n",
       "7            balanced            l2    liblinear   \n",
       "13           balanced            l2    liblinear   \n",
       "9            balanced            l2    liblinear   \n",
       "1            balanced            l2    liblinear   \n",
       "3            balanced            l2    liblinear   \n",
       "5            balanced            l2    liblinear   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "2   {'C': 0.5, 'class_weight': 'balanced', 'penalt...           0.510411   \n",
       "6   {'C': 1, 'class_weight': 'balanced', 'penalty'...           0.514148   \n",
       "4   {'C': 0.7, 'class_weight': 'balanced', 'penalt...           0.514682   \n",
       "11  {'C': 10, 'class_weight': 'balanced', 'penalty...           0.515216   \n",
       "7   {'C': 1, 'class_weight': 'balanced', 'penalty'...           0.515216   \n",
       "13  {'C': 15, 'class_weight': 'balanced', 'penalty...           0.516284   \n",
       "9   {'C': 7, 'class_weight': 'balanced', 'penalty'...           0.515750   \n",
       "1   {'C': 0.1, 'class_weight': 'balanced', 'penalt...           0.507208   \n",
       "3   {'C': 0.5, 'class_weight': 'balanced', 'penalt...           0.510411   \n",
       "5   {'C': 0.7, 'class_weight': 'balanced', 'penalt...           0.513615   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "2            0.531767           0.556327           0.532585         0.532773   \n",
       "6            0.532301           0.560064           0.519765         0.531570   \n",
       "4            0.532835           0.557928           0.518697         0.531036   \n",
       "11           0.533369           0.556327           0.518697         0.530902   \n",
       "7            0.531767           0.553657           0.521368         0.530502   \n",
       "13           0.535505           0.554191           0.516026         0.530501   \n",
       "9            0.528564           0.556327           0.517094         0.529434   \n",
       "1            0.524826           0.553123           0.532051         0.529302   \n",
       "3            0.532301           0.557395           0.514957         0.528766   \n",
       "5            0.532301           0.552589           0.515491         0.528499   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "2         0.016247                1  \n",
       "6         0.017715                2  \n",
       "4         0.016927                3  \n",
       "11        0.016183                4  \n",
       "7         0.014619                5  \n",
       "13        0.015795                6  \n",
       "9         0.016306                7  \n",
       "1         0.016456                8  \n",
       "3         0.018437                9  \n",
       "5         0.015697               10  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_cv_sent.cv_results_).sort_values(['rank_test_score'])\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.5, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best score may lie between C=[0.1, 10], l1 or l2, need deeper search\n",
    "best_sent_wgt_params = results[results['param_class_weight'] == \"balanced\"].head(1)['params'].values[0]\n",
    "best_sent_wgt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sent_logit_wgt = LogisticRegression(random_state=1, **best_sent_wgt_params)\n",
    "best_sent_logit_wgt.fit(x_mix_train, y_sent_train)\n",
    "best_sent_wgt_pred = best_sent_logit_wgt.predict(x_mix_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.52      0.48      0.50       779\n",
      "     neutral       0.60      0.71      0.65      1152\n",
      "    positive       0.46      0.33      0.39       566\n",
      "\n",
      "    accuracy                           0.55      2497\n",
      "   macro avg       0.53      0.51      0.51      2497\n",
      "weighted avg       0.54      0.55      0.54      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_sent_test, best_sent_wgt_pred, target_names=sentiments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unweighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.5, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best score may lie between C=[0.1, 10], l1 or l2, need deeper search\n",
    "best_sent_unwgt_params = results.head(1)['params'].values[0]\n",
    "best_sent_unwgt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sent_logit_unwgt = LogisticRegression(random_state=1, **best_sent_unwgt_params)\n",
    "best_sent_logit_unwgt.fit(x_mix_train, y_sent_train)\n",
    "best_sent_unwgt_pred = best_sent_logit_unwgt.predict(x_mix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.55      0.36      0.44       779\n",
      "     neutral       0.55      0.84      0.66      1152\n",
      "    positive       0.51      0.22      0.31       566\n",
      "\n",
      "    accuracy                           0.55      2497\n",
      "   macro avg       0.54      0.47      0.47      2497\n",
      "weighted avg       0.54      0.55      0.51      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_sent_test, best_sent_unwgt_pred, target_names=sentiments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to solve the problem of always predicting the neurtral class\n",
    "\n",
    "Changing learning rate helps\n",
    "Added more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reference: https://www.dlology.com/blog/multi-class-classification-with-focal-loss-for-imbalanced-datasets/\n",
    "def focal_loss(gamma=2., alpha=4.):\n",
    "\n",
    "    gamma = float(gamma)\n",
    "    alpha = float(alpha)\n",
    "\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"Focal loss for multi-classification\n",
    "        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n",
    "        Notice: y_pred is probability after softmax\n",
    "        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n",
    "        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n",
    "        Focal Loss for Dense Object Detection\n",
    "        https://arxiv.org/abs/1708.02002\n",
    "\n",
    "        Arguments:\n",
    "            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n",
    "            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n",
    "\n",
    "        Keyword Arguments:\n",
    "            gamma {float} -- (default: {2.0})\n",
    "            alpha {float} -- (default: {4.0})\n",
    "\n",
    "        Returns:\n",
    "            [tensor] -- loss.\n",
    "        \"\"\"\n",
    "        epsilon = 1.e-9\n",
    "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
    "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
    "\n",
    "        model_out = tf.add(y_pred, epsilon)\n",
    "        ce = tf.multiply(y_true, -tf.log(model_out))\n",
    "        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n",
    "        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
    "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
    "        return tf.reduce_mean(reduced_fl)\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model3 = models.Sequential()\n",
    "nn_model3.add(Dense(64, activation='tanh', input_shape=(input_shape, ), kernel_constraint=min_max_norm(-3, 3), bias_constraint=unit_norm(),\\\n",
    "                    kernel_initializer=RandomUniform(minval=-0.1, maxval=+0.1)))\n",
    "nn_model3.add(Dense(32, activation='tanh', kernel_constraint=min_max_norm(-2, 2), bias_constraint=unit_norm()))\n",
    "nn_model3.add(Dense(16, activation='tanh'))\n",
    "nn_model3.add(Dropout(0.2))\n",
    "nn_model3.add(Dense(16, activation='tanh', kernel_constraint=min_max_norm(-3, 3), bias_constraint=unit_norm()))\n",
    "nn_model3.add(Dropout(0.2))\n",
    "nn_model3.add(Dense(7, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.00001)\n",
    "nn_model3.compile(loss=focal_loss(alpha=1), optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 00002: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "history2 = nn_model3.fit(x_arr_train, y_1hot_train, epochs=15, batch_size=128, validation_split=0.2, verbose=0, callbacks=[es]) \n",
    "\n",
    "\n",
    "# history2 = nn_model3.fit(x_arr_train, y_1hot_train, epochs=15, batch_size=128, validation_split=0.2, verbose=0) #, callbacks=[es]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history2.history['loss']\n",
    "val_loss = history2.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history2.history['categorical_accuracy']\n",
    "val_acc = history2.history['val_categorical_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.46      1.00      0.63      1152\n",
      "    surprise       0.00      0.00      0.00       329\n",
      "        fear       0.00      0.00      0.00        57\n",
      "     sadness       0.00      0.00      0.00       160\n",
      "         joy       0.00      0.00      0.00       422\n",
      "     disgust       0.00      0.00      0.00        65\n",
      "       anger       0.00      0.00      0.00       312\n",
      "\n",
      "    accuracy                           0.46      2497\n",
      "   macro avg       0.07      0.14      0.09      2497\n",
      "weighted avg       0.21      0.46      0.29      2497\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_nn_predict3 = nn_model3.predict(x_arr_test)\n",
    "print(classification_report(np.argmax(y_1hot_test, axis=1), np.argmax(y_nn_predict3, axis=1), target_names=emotions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{4: 1521, 1: 1076, 2: 411, 5: 406, 6: 997, 3: 723},\n",
       " {4: 1821, 1: 1376, 2: 711, 5: 706, 6: 1297, 3: 1023},\n",
       " {4: 2121, 1: 1676, 2: 1011, 5: 1006, 6: 1597, 3: 1323}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = Counter(y_num_train)\n",
    "\n",
    "over_dicts = []\n",
    "for delta in [200, 500, 800]:\n",
    "    resample_dict = {l: ct + delta for l, ct in label_counts.items() if l != 0}\n",
    "#     resample_dict[0] -= delta\n",
    "    over_dicts.append(resample_dict)\n",
    "\n",
    "under_dicts = []\n",
    "for delta in [200, 500, 1000]:\n",
    "    resample_dict = {0: 2963 - delta}\n",
    "    under_dicts.append(resample_dict)\n",
    "    \n",
    "\n",
    "neutral_count = int(3557 * 5/6)\n",
    "\n",
    "Counter(y_num_train)\n",
    "over_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 4709, 1: 1405, 2: 468, 3: 883, 4: 1943, 5: 471, 6: 1309}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 3000, 4: 1943, 1: 1405, 6: 1309, 3: 883, 5: 471, 2: 468})\n"
     ]
    }
   ],
   "source": [
    "under = RandomUnderSampler(sampling_strategy={0: 3000})\n",
    "x_new_train, y_new_train = under.fit_resample(x_new_train, y_new_train)\n",
    "\n",
    "print(Counter(y_new_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrappedSMOTE(label_counts=label_counts, delta=200, k=5):\n",
    "    \"\"\"wrapped SMOTE for pipline/gridsearch\"\"\"\n",
    "    resample_dict = {l: ct + delta for l, ct in label_counts.items()}\n",
    "    resample_dict[0] -= delta\n",
    "    smote = SMOTE(sampling_strategy=resample_dict, k_neighbors=k)\n",
    "    return smote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrappedRUS(delta=200):\n",
    "    \"\"\"wrapped RandomUnderSampler for pipline/gridsearch\"\"\"\n",
    "    resample_dict = {0: 3557 - delta}\n",
    "    rus = RandomUnderSampler(sampling_strategy=resample_dict)\n",
    "    return rus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 3557, 4: 3321, 1: 2876, 6: 2797, 3: 2523, 2: 2211, 5: 2206})\n"
     ]
    }
   ],
   "source": [
    "temp= wrappedSMOTE(delta=2000)\n",
    "x_new_train, y_new_train = temp.fit_resample(x_mix_train, y_num_train)\n",
    "print(Counter(y_new_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=1)\n",
    "over = RandomOverSampler()\n",
    "under = RandomUnderSampler() # random\n",
    "pipe = imblearn.pipeline.Pipeline(steps=[('o', over), ('u', under), ('m', model)])\n",
    "\n",
    "# over.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGKILL(-9), SIGKILL(-9), SIGKILL(-9)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a7c45b0073f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRepeatedStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mix_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_num_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1_weighted'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mean f1_weighted: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/speech_gen/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[1;32m    386\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/speech_gen/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    228\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[1;32m    229\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m--> 230\u001b[0;31m     scores = parallel(\n\u001b[0m\u001b[1;32m    231\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    232\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/speech_gen/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/speech_gen/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/speech_gen/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/speech_gen/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/speech_gen/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGKILL(-9), SIGKILL(-9), SIGKILL(-9)}"
     ]
    }
   ],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipe, x_mix_train, y_num_train, scoring='f1_weighted', cv=cv, n_jobs=-1)\n",
    "print('Mean f1_weighted: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7491"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(label_counts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11497"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Counter(y_new_train).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Using backend LokyBackend with 32 concurrent workers.\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGKILL(-9), SIGKILL(-9)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-465dad0d8538>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Create grid search object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgrid_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"f1_weighted\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mix_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_num_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rank_test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/speech_gen/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/speech_gen/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/speech_gen/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    680\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    683\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/speech_gen/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/speech_gen/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/speech_gen/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/speech_gen/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/speech_gen/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGKILL(-9), SIGKILL(-9)}"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'o__sampling_strategy': over_dicts,\n",
    "#     'o__k_neighbors': [3, 5, 7, 9],\n",
    "    'u__sampling_strategy': under_dicts,\n",
    "    'm__penalty' : ['l1', 'l2'],\n",
    "    'm__class_weight': ['balanced', None],\n",
    "    'm__C' : [1, 5, 10, 100, 1000],\n",
    "    'm__solver' : ['liblinear']}\n",
    "\n",
    "# Create grid search object\n",
    "grid_cv = GridSearchCV(pipe, param_grid = param_grid, scoring=\"f1_weighted\", cv = 5, verbose=2, n_jobs=32).fit(x_mix_train, y_num_train)\n",
    "\n",
    "results = pd.DataFrame(grid_cv.cv_results_).sort_values(['rank_test_score'])\n",
    "results.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-f3761b7ac4fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_cv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_cv' is not defined"
     ]
    }
   ],
   "source": [
    "grid_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=[\"anger\", \"disgust\", \"fear\", \"joy\", \"neutral\", \"sadness\", \"surprise\"]\n",
    "labels_ordered = [emo2int[x] for x in temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2763, 4: 1821, 1: 1376, 6: 1297, 3: 1023, 2: 711, 5: 706})\n"
     ]
    }
   ],
   "source": [
    "# print(label_counts)\n",
    "# maj_count = label_counts[0]\n",
    "# delta = 200\n",
    "# resample_dict = {}\n",
    "# for l, ct in label_counts.items():\n",
    "# #     print(f\"{l}: {ct/maj_count: .2f}\")\n",
    "#     resample_dict[l] = ct + delta\n",
    "#     print(f\"{l}: {resample_dict[l] / maj_count: .2f}\")\n",
    "    \n",
    "# resample_dict[0] -= delta\n",
    "over = SMOTE(sampling_strategy=over_dicts[1], k_neighbors=10)\n",
    "under = RandomUnderSampler(sampling_strategy=under_dicts[0])\n",
    "x_new_train, y_new_train = over.fit_resample(x_mix_train, y_num_train)\n",
    "x_new_train, y_new_train = under.fit_resample(x_new_train, y_new_train)\n",
    "\n",
    "print(Counter(y_new_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 14 candidates, totalling 98 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 36 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  77 out of  98 | elapsed:  3.4min remaining:   55.2s\n",
      "[Parallel(n_jobs=-1)]: Done  98 out of  98 | elapsed:  4.3min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'penalty' : ['l1', 'l2'],\n",
    "    'class_weight': [ None],\n",
    "    'C' : [1, 10, 15, 20, 50, 100, 200],\n",
    "    'solver' : ['liblinear']}\n",
    "\n",
    "# Create grid search object\n",
    "logit = LogisticRegression(random_state=1)\n",
    "grid_cv = GridSearchCV(logit, param_grid = param_grid, cv = 7, verbose=2, n_jobs=-1).fit(x_new_train, y_new_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>123.108476</td>\n",
       "      <td>16.871889</td>\n",
       "      <td>0.005504</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 20, 'class_weight': None, 'penalty': 'l1...</td>\n",
       "      <td>0.596398</td>\n",
       "      <td>0.580387</td>\n",
       "      <td>0.603069</td>\n",
       "      <td>0.607071</td>\n",
       "      <td>0.656438</td>\n",
       "      <td>0.742991</td>\n",
       "      <td>0.753004</td>\n",
       "      <td>0.648480</td>\n",
       "      <td>0.066598</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>103.822872</td>\n",
       "      <td>15.831743</td>\n",
       "      <td>0.005849</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 5, 'class_weight': None, 'penalty': 'l1'...</td>\n",
       "      <td>0.595730</td>\n",
       "      <td>0.591728</td>\n",
       "      <td>0.594396</td>\n",
       "      <td>0.609073</td>\n",
       "      <td>0.658439</td>\n",
       "      <td>0.734312</td>\n",
       "      <td>0.739653</td>\n",
       "      <td>0.646190</td>\n",
       "      <td>0.061206</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>137.591704</td>\n",
       "      <td>32.550447</td>\n",
       "      <td>0.009857</td>\n",
       "      <td>0.005638</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 100, 'class_weight': None, 'penalty': 'l...</td>\n",
       "      <td>0.579053</td>\n",
       "      <td>0.574383</td>\n",
       "      <td>0.596398</td>\n",
       "      <td>0.602402</td>\n",
       "      <td>0.656438</td>\n",
       "      <td>0.744993</td>\n",
       "      <td>0.751669</td>\n",
       "      <td>0.643619</td>\n",
       "      <td>0.070718</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>133.427174</td>\n",
       "      <td>11.621387</td>\n",
       "      <td>0.008219</td>\n",
       "      <td>0.005144</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 50, 'class_weight': None, 'penalty': 'l1...</td>\n",
       "      <td>0.579720</td>\n",
       "      <td>0.576384</td>\n",
       "      <td>0.598399</td>\n",
       "      <td>0.602402</td>\n",
       "      <td>0.652435</td>\n",
       "      <td>0.742323</td>\n",
       "      <td>0.749666</td>\n",
       "      <td>0.643047</td>\n",
       "      <td>0.069087</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>128.798480</td>\n",
       "      <td>14.023403</td>\n",
       "      <td>0.005232</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 200, 'class_weight': None, 'penalty': 'l...</td>\n",
       "      <td>0.573049</td>\n",
       "      <td>0.570380</td>\n",
       "      <td>0.594396</td>\n",
       "      <td>0.601067</td>\n",
       "      <td>0.654436</td>\n",
       "      <td>0.740988</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.641618</td>\n",
       "      <td>0.072708</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>147.836307</td>\n",
       "      <td>37.810413</td>\n",
       "      <td>0.005285</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>20</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 20, 'class_weight': 'balanced', 'penalty...</td>\n",
       "      <td>0.574383</td>\n",
       "      <td>0.577718</td>\n",
       "      <td>0.585057</td>\n",
       "      <td>0.603736</td>\n",
       "      <td>0.641761</td>\n",
       "      <td>0.732977</td>\n",
       "      <td>0.749666</td>\n",
       "      <td>0.637900</td>\n",
       "      <td>0.068829</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100.555070</td>\n",
       "      <td>18.467646</td>\n",
       "      <td>0.005412</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 5, 'class_weight': 'balanced', 'penalty'...</td>\n",
       "      <td>0.578386</td>\n",
       "      <td>0.570380</td>\n",
       "      <td>0.588392</td>\n",
       "      <td>0.605070</td>\n",
       "      <td>0.647098</td>\n",
       "      <td>0.726969</td>\n",
       "      <td>0.732977</td>\n",
       "      <td>0.635610</td>\n",
       "      <td>0.063976</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>127.165115</td>\n",
       "      <td>28.482574</td>\n",
       "      <td>0.004749</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1000, 'class_weight': None, 'penalty': '...</td>\n",
       "      <td>0.567712</td>\n",
       "      <td>0.561708</td>\n",
       "      <td>0.581054</td>\n",
       "      <td>0.594396</td>\n",
       "      <td>0.643095</td>\n",
       "      <td>0.742323</td>\n",
       "      <td>0.751001</td>\n",
       "      <td>0.634470</td>\n",
       "      <td>0.075116</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>161.973315</td>\n",
       "      <td>30.933308</td>\n",
       "      <td>0.005681</td>\n",
       "      <td>0.001075</td>\n",
       "      <td>50</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 50, 'class_weight': 'balanced', 'penalty...</td>\n",
       "      <td>0.567712</td>\n",
       "      <td>0.569713</td>\n",
       "      <td>0.589726</td>\n",
       "      <td>0.598399</td>\n",
       "      <td>0.638426</td>\n",
       "      <td>0.730307</td>\n",
       "      <td>0.746996</td>\n",
       "      <td>0.634468</td>\n",
       "      <td>0.069504</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>170.430797</td>\n",
       "      <td>24.393236</td>\n",
       "      <td>0.005632</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>100</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 100, 'class_weight': 'balanced', 'penalt...</td>\n",
       "      <td>0.569046</td>\n",
       "      <td>0.558372</td>\n",
       "      <td>0.585057</td>\n",
       "      <td>0.604403</td>\n",
       "      <td>0.635090</td>\n",
       "      <td>0.736315</td>\n",
       "      <td>0.749666</td>\n",
       "      <td>0.633993</td>\n",
       "      <td>0.072760</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "14     123.108476     16.871889         0.005504        0.000482      20   \n",
       "10     103.822872     15.831743         0.005849        0.000767       5   \n",
       "22     137.591704     32.550447         0.009857        0.005638     100   \n",
       "18     133.427174     11.621387         0.008219        0.005144      50   \n",
       "26     128.798480     14.023403         0.005232        0.000167     200   \n",
       "12     147.836307     37.810413         0.005285        0.000201      20   \n",
       "8      100.555070     18.467646         0.005412        0.000372       5   \n",
       "30     127.165115     28.482574         0.004749        0.000070    1000   \n",
       "16     161.973315     30.933308         0.005681        0.001075      50   \n",
       "20     170.430797     24.393236         0.005632        0.000925     100   \n",
       "\n",
       "   param_class_weight param_penalty param_solver  \\\n",
       "14               None            l1    liblinear   \n",
       "10               None            l1    liblinear   \n",
       "22               None            l1    liblinear   \n",
       "18               None            l1    liblinear   \n",
       "26               None            l1    liblinear   \n",
       "12           balanced            l1    liblinear   \n",
       "8            balanced            l1    liblinear   \n",
       "30               None            l1    liblinear   \n",
       "16           balanced            l1    liblinear   \n",
       "20           balanced            l1    liblinear   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "14  {'C': 20, 'class_weight': None, 'penalty': 'l1...           0.596398   \n",
       "10  {'C': 5, 'class_weight': None, 'penalty': 'l1'...           0.595730   \n",
       "22  {'C': 100, 'class_weight': None, 'penalty': 'l...           0.579053   \n",
       "18  {'C': 50, 'class_weight': None, 'penalty': 'l1...           0.579720   \n",
       "26  {'C': 200, 'class_weight': None, 'penalty': 'l...           0.573049   \n",
       "12  {'C': 20, 'class_weight': 'balanced', 'penalty...           0.574383   \n",
       "8   {'C': 5, 'class_weight': 'balanced', 'penalty'...           0.578386   \n",
       "30  {'C': 1000, 'class_weight': None, 'penalty': '...           0.567712   \n",
       "16  {'C': 50, 'class_weight': 'balanced', 'penalty...           0.567712   \n",
       "20  {'C': 100, 'class_weight': 'balanced', 'penalt...           0.569046   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "14           0.580387           0.603069           0.607071   \n",
       "10           0.591728           0.594396           0.609073   \n",
       "22           0.574383           0.596398           0.602402   \n",
       "18           0.576384           0.598399           0.602402   \n",
       "26           0.570380           0.594396           0.601067   \n",
       "12           0.577718           0.585057           0.603736   \n",
       "8            0.570380           0.588392           0.605070   \n",
       "30           0.561708           0.581054           0.594396   \n",
       "16           0.569713           0.589726           0.598399   \n",
       "20           0.558372           0.585057           0.604403   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  mean_test_score  \\\n",
       "14           0.656438           0.742991           0.753004         0.648480   \n",
       "10           0.658439           0.734312           0.739653         0.646190   \n",
       "22           0.656438           0.744993           0.751669         0.643619   \n",
       "18           0.652435           0.742323           0.749666         0.643047   \n",
       "26           0.654436           0.740988           0.757009         0.641618   \n",
       "12           0.641761           0.732977           0.749666         0.637900   \n",
       "8            0.647098           0.726969           0.732977         0.635610   \n",
       "30           0.643095           0.742323           0.751001         0.634470   \n",
       "16           0.638426           0.730307           0.746996         0.634468   \n",
       "20           0.635090           0.736315           0.749666         0.633993   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "14        0.066598                1  \n",
       "10        0.061206                2  \n",
       "22        0.070718                3  \n",
       "18        0.069087                4  \n",
       "26        0.072708                5  \n",
       "12        0.068829                6  \n",
       "8         0.063976                7  \n",
       "30        0.075116                8  \n",
       "16        0.069504                9  \n",
       "20        0.072760               10  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_cv.cv_results_).sort_values(['rank_test_score'])\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.26      0.22      0.24       312\n",
      "     disgust       0.13      0.14      0.14        65\n",
      "        fear       0.06      0.11      0.08        57\n",
      "         joy       0.34      0.32      0.33       422\n",
      "     neutral       0.57      0.58      0.57      1152\n",
      "     sadness       0.15      0.15      0.15       160\n",
      "    surprise       0.32      0.30      0.31       329\n",
      "\n",
      "    accuracy                           0.41      2497\n",
      "   macro avg       0.26      0.26      0.26      2497\n",
      "weighted avg       0.41      0.41      0.41      2497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logistic regression with oversampling\n",
    "best_logit = LogisticRegression(random_state=1, **grid_cv.best_params_)\n",
    "best_logit.fit(x_new_train, y_new_train)\n",
    "y_predict = best_logit.predict(x_mix_test)\n",
    "\n",
    "print(classification_report(y_num_test, y_predict, labels=labels_ordered, target_names=temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9988, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using audio embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 20)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.468404</td>\n",
       "      <td>0.278676</td>\n",
       "      <td>-0.466101</td>\n",
       "      <td>-0.841499</td>\n",
       "      <td>0.811462</td>\n",
       "      <td>0.994261</td>\n",
       "      <td>0.079472</td>\n",
       "      <td>0.331361</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>-0.652272</td>\n",
       "      <td>0.534986</td>\n",
       "      <td>-0.043683</td>\n",
       "      <td>0.237591</td>\n",
       "      <td>-0.517976</td>\n",
       "      <td>-0.125858</td>\n",
       "      <td>-0.664146</td>\n",
       "      <td>-0.092333</td>\n",
       "      <td>0.472566</td>\n",
       "      <td>-0.217704</td>\n",
       "      <td>-1.215915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.393439</td>\n",
       "      <td>-0.049780</td>\n",
       "      <td>0.540950</td>\n",
       "      <td>0.341101</td>\n",
       "      <td>-1.450056</td>\n",
       "      <td>-0.316093</td>\n",
       "      <td>0.223109</td>\n",
       "      <td>-0.665428</td>\n",
       "      <td>-0.001696</td>\n",
       "      <td>-0.214290</td>\n",
       "      <td>-0.177799</td>\n",
       "      <td>2.145403</td>\n",
       "      <td>-1.066256</td>\n",
       "      <td>1.891518</td>\n",
       "      <td>0.460961</td>\n",
       "      <td>-2.707002</td>\n",
       "      <td>1.432687</td>\n",
       "      <td>1.104046</td>\n",
       "      <td>-0.708277</td>\n",
       "      <td>0.283212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.242229</td>\n",
       "      <td>-0.049403</td>\n",
       "      <td>0.381951</td>\n",
       "      <td>-0.164425</td>\n",
       "      <td>-2.974038</td>\n",
       "      <td>0.140854</td>\n",
       "      <td>1.391142</td>\n",
       "      <td>-1.324422</td>\n",
       "      <td>1.446847</td>\n",
       "      <td>0.098883</td>\n",
       "      <td>-0.528462</td>\n",
       "      <td>3.522814</td>\n",
       "      <td>-1.228283</td>\n",
       "      <td>1.477336</td>\n",
       "      <td>0.621532</td>\n",
       "      <td>-2.735992</td>\n",
       "      <td>0.292453</td>\n",
       "      <td>-0.049170</td>\n",
       "      <td>-1.240625</td>\n",
       "      <td>0.957958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.236312</td>\n",
       "      <td>-0.058175</td>\n",
       "      <td>0.145887</td>\n",
       "      <td>-0.038939</td>\n",
       "      <td>-0.915901</td>\n",
       "      <td>-0.452194</td>\n",
       "      <td>0.519279</td>\n",
       "      <td>-0.432044</td>\n",
       "      <td>0.827844</td>\n",
       "      <td>0.061658</td>\n",
       "      <td>-0.133397</td>\n",
       "      <td>1.377155</td>\n",
       "      <td>-0.490001</td>\n",
       "      <td>0.785380</td>\n",
       "      <td>-0.090981</td>\n",
       "      <td>-1.176765</td>\n",
       "      <td>0.576154</td>\n",
       "      <td>0.372343</td>\n",
       "      <td>-0.720053</td>\n",
       "      <td>0.481285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.494084</td>\n",
       "      <td>-0.414193</td>\n",
       "      <td>0.686100</td>\n",
       "      <td>-0.079510</td>\n",
       "      <td>-2.225597</td>\n",
       "      <td>0.112894</td>\n",
       "      <td>0.940339</td>\n",
       "      <td>-1.034066</td>\n",
       "      <td>0.878203</td>\n",
       "      <td>-0.171336</td>\n",
       "      <td>-0.101157</td>\n",
       "      <td>2.875808</td>\n",
       "      <td>-0.771293</td>\n",
       "      <td>1.821688</td>\n",
       "      <td>0.622958</td>\n",
       "      <td>-2.121955</td>\n",
       "      <td>1.127253</td>\n",
       "      <td>1.203245</td>\n",
       "      <td>-0.917203</td>\n",
       "      <td>0.686002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>0.317646</td>\n",
       "      <td>0.127494</td>\n",
       "      <td>0.561333</td>\n",
       "      <td>-0.170620</td>\n",
       "      <td>-2.089635</td>\n",
       "      <td>-0.319585</td>\n",
       "      <td>0.702855</td>\n",
       "      <td>-0.999539</td>\n",
       "      <td>1.182079</td>\n",
       "      <td>0.222808</td>\n",
       "      <td>-0.081520</td>\n",
       "      <td>2.877434</td>\n",
       "      <td>-0.913109</td>\n",
       "      <td>1.734860</td>\n",
       "      <td>-0.157258</td>\n",
       "      <td>-2.513618</td>\n",
       "      <td>0.939858</td>\n",
       "      <td>1.602317</td>\n",
       "      <td>-1.390440</td>\n",
       "      <td>0.395372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>-0.254540</td>\n",
       "      <td>0.392315</td>\n",
       "      <td>2.296835</td>\n",
       "      <td>-1.325808</td>\n",
       "      <td>-3.301410</td>\n",
       "      <td>-0.205515</td>\n",
       "      <td>2.201517</td>\n",
       "      <td>-1.735718</td>\n",
       "      <td>2.608117</td>\n",
       "      <td>0.042434</td>\n",
       "      <td>-1.344730</td>\n",
       "      <td>4.906795</td>\n",
       "      <td>-0.918109</td>\n",
       "      <td>0.927062</td>\n",
       "      <td>1.368234</td>\n",
       "      <td>-2.642496</td>\n",
       "      <td>-0.844671</td>\n",
       "      <td>0.537211</td>\n",
       "      <td>-1.962808</td>\n",
       "      <td>0.413894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>-0.025878</td>\n",
       "      <td>-0.096097</td>\n",
       "      <td>0.010346</td>\n",
       "      <td>0.005652</td>\n",
       "      <td>-0.669789</td>\n",
       "      <td>-0.851164</td>\n",
       "      <td>0.641215</td>\n",
       "      <td>-0.100471</td>\n",
       "      <td>0.936295</td>\n",
       "      <td>0.300127</td>\n",
       "      <td>-0.186234</td>\n",
       "      <td>1.266441</td>\n",
       "      <td>-0.496933</td>\n",
       "      <td>0.685078</td>\n",
       "      <td>-0.470907</td>\n",
       "      <td>-0.906288</td>\n",
       "      <td>0.549094</td>\n",
       "      <td>0.835844</td>\n",
       "      <td>-0.940960</td>\n",
       "      <td>0.552636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>0.229676</td>\n",
       "      <td>0.241477</td>\n",
       "      <td>1.348317</td>\n",
       "      <td>-0.423532</td>\n",
       "      <td>-2.928809</td>\n",
       "      <td>0.004402</td>\n",
       "      <td>1.284401</td>\n",
       "      <td>-1.472378</td>\n",
       "      <td>1.175798</td>\n",
       "      <td>-0.138858</td>\n",
       "      <td>-0.212625</td>\n",
       "      <td>3.868988</td>\n",
       "      <td>-1.018544</td>\n",
       "      <td>1.744546</td>\n",
       "      <td>1.180914</td>\n",
       "      <td>-2.500556</td>\n",
       "      <td>0.760446</td>\n",
       "      <td>1.459516</td>\n",
       "      <td>-1.314147</td>\n",
       "      <td>0.297955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>0.173511</td>\n",
       "      <td>0.080043</td>\n",
       "      <td>0.614881</td>\n",
       "      <td>0.174859</td>\n",
       "      <td>-1.877890</td>\n",
       "      <td>-0.434028</td>\n",
       "      <td>0.575739</td>\n",
       "      <td>-0.719124</td>\n",
       "      <td>1.013039</td>\n",
       "      <td>0.037704</td>\n",
       "      <td>-0.062410</td>\n",
       "      <td>2.350066</td>\n",
       "      <td>-0.875354</td>\n",
       "      <td>1.180253</td>\n",
       "      <td>0.016741</td>\n",
       "      <td>-1.993272</td>\n",
       "      <td>0.762353</td>\n",
       "      <td>1.421206</td>\n",
       "      <td>-1.124411</td>\n",
       "      <td>0.320727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.468404  0.278676 -0.466101 -0.841499  0.811462  0.994261  0.079472   \n",
       "1     0.393439 -0.049780  0.540950  0.341101 -1.450056 -0.316093  0.223109   \n",
       "2     0.242229 -0.049403  0.381951 -0.164425 -2.974038  0.140854  1.391142   \n",
       "3     0.236312 -0.058175  0.145887 -0.038939 -0.915901 -0.452194  0.519279   \n",
       "4     0.494084 -0.414193  0.686100 -0.079510 -2.225597  0.112894  0.940339   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9984  0.317646  0.127494  0.561333 -0.170620 -2.089635 -0.319585  0.702855   \n",
       "9985 -0.254540  0.392315  2.296835 -1.325808 -3.301410 -0.205515  2.201517   \n",
       "9986 -0.025878 -0.096097  0.010346  0.005652 -0.669789 -0.851164  0.641215   \n",
       "9987  0.229676  0.241477  1.348317 -0.423532 -2.928809  0.004402  1.284401   \n",
       "9988  0.173511  0.080043  0.614881  0.174859 -1.877890 -0.434028  0.575739   \n",
       "\n",
       "             7         8         9        10        11        12        13  \\\n",
       "0     0.331361  0.709990 -0.652272  0.534986 -0.043683  0.237591 -0.517976   \n",
       "1    -0.665428 -0.001696 -0.214290 -0.177799  2.145403 -1.066256  1.891518   \n",
       "2    -1.324422  1.446847  0.098883 -0.528462  3.522814 -1.228283  1.477336   \n",
       "3    -0.432044  0.827844  0.061658 -0.133397  1.377155 -0.490001  0.785380   \n",
       "4    -1.034066  0.878203 -0.171336 -0.101157  2.875808 -0.771293  1.821688   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9984 -0.999539  1.182079  0.222808 -0.081520  2.877434 -0.913109  1.734860   \n",
       "9985 -1.735718  2.608117  0.042434 -1.344730  4.906795 -0.918109  0.927062   \n",
       "9986 -0.100471  0.936295  0.300127 -0.186234  1.266441 -0.496933  0.685078   \n",
       "9987 -1.472378  1.175798 -0.138858 -0.212625  3.868988 -1.018544  1.744546   \n",
       "9988 -0.719124  1.013039  0.037704 -0.062410  2.350066 -0.875354  1.180253   \n",
       "\n",
       "            14        15        16        17        18        19  \n",
       "0    -0.125858 -0.664146 -0.092333  0.472566 -0.217704 -1.215915  \n",
       "1     0.460961 -2.707002  1.432687  1.104046 -0.708277  0.283212  \n",
       "2     0.621532 -2.735992  0.292453 -0.049170 -1.240625  0.957958  \n",
       "3    -0.090981 -1.176765  0.576154  0.372343 -0.720053  0.481285  \n",
       "4     0.622958 -2.121955  1.127253  1.203245 -0.917203  0.686002  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "9984 -0.157258 -2.513618  0.939858  1.602317 -1.390440  0.395372  \n",
       "9985  1.368234 -2.642496 -0.844671  0.537211 -1.962808  0.413894  \n",
       "9986 -0.470907 -0.906288  0.549094  0.835844 -0.940960  0.552636  \n",
       "9987  1.180914 -2.500556  0.760446  1.459516 -1.314147  0.297955  \n",
       "9988  0.016741 -1.993272  0.762353  1.421206 -1.124411  0.320727  \n",
       "\n",
       "[9000 rows x 20 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_emb_raw = pd.read_csv(\"../data/audio_embeddings.csv\", index_col=0)\n",
    "\n",
    "mapping_df = train_df[[\"Dialogue_ID\", \"Utterance_ID\"]].copy()\n",
    "mapping_df['name'] = mapping_df.apply(lambda x: f\"dia{x['Dialogue_ID']}_utt{x['Utterance_ID']}\", axis=1)\n",
    "mapping_df = mapping_df.drop(columns=[\"Dialogue_ID\", \"Utterance_ID\"])\n",
    "mapping_df.head()\n",
    "\n",
    "audio_emb = pd.merge(mapping_df, audio_emb_raw, left_on=\"name\", right_index=True, how=\"inner\")\n",
    "audio_emb = audio_emb.drop(columns=['name'])\n",
    "audio_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_emb_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dia0_utt5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dia0_utt7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>dia2_utt4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>dia3_utt6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>dia5_utt0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9936</th>\n",
       "      <td>dia1034_utt0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9945</th>\n",
       "      <td>dia1035_utt6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9955</th>\n",
       "      <td>dia1036_utt9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9966</th>\n",
       "      <td>dia1036_utt20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>dia1038_utt12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>988 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               name   0   1   2   3   4   5   6   7   8  ...  10  11  12  13  \\\n",
       "5         dia0_utt5 NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN   \n",
       "7         dia0_utt7 NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN   \n",
       "25        dia2_utt4 NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN   \n",
       "40        dia3_utt6 NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN   \n",
       "58        dia5_utt0 NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN   \n",
       "...             ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..   \n",
       "9936   dia1034_utt0 NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN   \n",
       "9945   dia1035_utt6 NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN   \n",
       "9955   dia1036_utt9 NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN   \n",
       "9966  dia1036_utt20 NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN   \n",
       "9982  dia1038_utt12 NaN NaN NaN NaN NaN NaN NaN NaN NaN  ... NaN NaN NaN NaN   \n",
       "\n",
       "      14  15  16  17  18  19  \n",
       "5    NaN NaN NaN NaN NaN NaN  \n",
       "7    NaN NaN NaN NaN NaN NaN  \n",
       "25   NaN NaN NaN NaN NaN NaN  \n",
       "40   NaN NaN NaN NaN NaN NaN  \n",
       "58   NaN NaN NaN NaN NaN NaN  \n",
       "...   ..  ..  ..  ..  ..  ..  \n",
       "9936 NaN NaN NaN NaN NaN NaN  \n",
       "9945 NaN NaN NaN NaN NaN NaN  \n",
       "9955 NaN NaN NaN NaN NaN NaN  \n",
       "9966 NaN NaN NaN NaN NaN NaN  \n",
       "9982 NaN NaN NaN NaN NaN NaN  \n",
       "\n",
       "[988 rows x 21 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_emb[audio_emb.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = pd.merge(x_txt_train.to_frame(), audio_emb, left_index=True, right_index=True, how='inner').drop(columns=['cleaned_Utterance'])\n",
    "test_subset = pd.merge(x_txt_test.to_frame(), audio_emb, left_index=True, right_index=True).drop(columns=['cleaned_Utterance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>0.380136</td>\n",
       "      <td>0.013557</td>\n",
       "      <td>0.444868</td>\n",
       "      <td>-0.159154</td>\n",
       "      <td>-1.882184</td>\n",
       "      <td>-0.540239</td>\n",
       "      <td>0.408776</td>\n",
       "      <td>-1.003661</td>\n",
       "      <td>0.658224</td>\n",
       "      <td>-0.132428</td>\n",
       "      <td>-0.003633</td>\n",
       "      <td>2.374494</td>\n",
       "      <td>-0.924737</td>\n",
       "      <td>1.911677</td>\n",
       "      <td>0.182614</td>\n",
       "      <td>-2.683055</td>\n",
       "      <td>1.372901</td>\n",
       "      <td>1.415666</td>\n",
       "      <td>-1.037116</td>\n",
       "      <td>0.627431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9873</th>\n",
       "      <td>0.289691</td>\n",
       "      <td>-0.109464</td>\n",
       "      <td>-0.062073</td>\n",
       "      <td>0.069794</td>\n",
       "      <td>-0.060432</td>\n",
       "      <td>-0.338151</td>\n",
       "      <td>0.501673</td>\n",
       "      <td>0.022923</td>\n",
       "      <td>1.027111</td>\n",
       "      <td>-0.157100</td>\n",
       "      <td>0.306545</td>\n",
       "      <td>0.721678</td>\n",
       "      <td>0.282060</td>\n",
       "      <td>1.033581</td>\n",
       "      <td>-0.337916</td>\n",
       "      <td>-1.303151</td>\n",
       "      <td>0.790982</td>\n",
       "      <td>1.671680</td>\n",
       "      <td>-0.667830</td>\n",
       "      <td>0.188300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2542</th>\n",
       "      <td>0.051725</td>\n",
       "      <td>0.014099</td>\n",
       "      <td>-0.670242</td>\n",
       "      <td>0.301025</td>\n",
       "      <td>0.911384</td>\n",
       "      <td>-0.825443</td>\n",
       "      <td>-0.268050</td>\n",
       "      <td>0.684835</td>\n",
       "      <td>0.127059</td>\n",
       "      <td>0.184599</td>\n",
       "      <td>0.328975</td>\n",
       "      <td>-0.417977</td>\n",
       "      <td>0.437139</td>\n",
       "      <td>0.252209</td>\n",
       "      <td>-0.898743</td>\n",
       "      <td>-0.021114</td>\n",
       "      <td>0.432363</td>\n",
       "      <td>0.385303</td>\n",
       "      <td>0.062679</td>\n",
       "      <td>0.707053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>0.184398</td>\n",
       "      <td>-0.174997</td>\n",
       "      <td>1.742006</td>\n",
       "      <td>-0.606104</td>\n",
       "      <td>-2.578461</td>\n",
       "      <td>-0.553388</td>\n",
       "      <td>1.377012</td>\n",
       "      <td>-1.053009</td>\n",
       "      <td>1.777836</td>\n",
       "      <td>-0.157670</td>\n",
       "      <td>-0.558999</td>\n",
       "      <td>3.678346</td>\n",
       "      <td>-0.997593</td>\n",
       "      <td>1.036072</td>\n",
       "      <td>0.981599</td>\n",
       "      <td>-1.818053</td>\n",
       "      <td>0.708083</td>\n",
       "      <td>1.311199</td>\n",
       "      <td>-1.387904</td>\n",
       "      <td>0.121383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8653</th>\n",
       "      <td>0.273693</td>\n",
       "      <td>0.029989</td>\n",
       "      <td>-0.293199</td>\n",
       "      <td>0.162781</td>\n",
       "      <td>0.058210</td>\n",
       "      <td>-0.401742</td>\n",
       "      <td>-0.079954</td>\n",
       "      <td>0.093336</td>\n",
       "      <td>0.364464</td>\n",
       "      <td>-0.062191</td>\n",
       "      <td>0.248690</td>\n",
       "      <td>0.318145</td>\n",
       "      <td>-0.248417</td>\n",
       "      <td>0.583351</td>\n",
       "      <td>-0.554918</td>\n",
       "      <td>-0.944436</td>\n",
       "      <td>0.633883</td>\n",
       "      <td>1.261529</td>\n",
       "      <td>-0.604498</td>\n",
       "      <td>0.177346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>0.426053</td>\n",
       "      <td>0.128535</td>\n",
       "      <td>0.595150</td>\n",
       "      <td>0.171173</td>\n",
       "      <td>-1.627591</td>\n",
       "      <td>-0.138677</td>\n",
       "      <td>0.623442</td>\n",
       "      <td>-0.846837</td>\n",
       "      <td>0.867146</td>\n",
       "      <td>0.161239</td>\n",
       "      <td>0.045224</td>\n",
       "      <td>2.244308</td>\n",
       "      <td>-0.722979</td>\n",
       "      <td>1.328255</td>\n",
       "      <td>0.217344</td>\n",
       "      <td>-1.890015</td>\n",
       "      <td>0.727113</td>\n",
       "      <td>1.181411</td>\n",
       "      <td>-0.963641</td>\n",
       "      <td>0.026678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>0.235136</td>\n",
       "      <td>-0.023087</td>\n",
       "      <td>0.553511</td>\n",
       "      <td>-0.039840</td>\n",
       "      <td>-1.806681</td>\n",
       "      <td>-0.424436</td>\n",
       "      <td>0.561687</td>\n",
       "      <td>-1.063671</td>\n",
       "      <td>1.194095</td>\n",
       "      <td>-0.208619</td>\n",
       "      <td>-0.022236</td>\n",
       "      <td>2.639043</td>\n",
       "      <td>-0.603684</td>\n",
       "      <td>1.461889</td>\n",
       "      <td>0.264556</td>\n",
       "      <td>-2.185811</td>\n",
       "      <td>1.075058</td>\n",
       "      <td>1.943642</td>\n",
       "      <td>-1.133654</td>\n",
       "      <td>0.504604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0.026033</td>\n",
       "      <td>0.291060</td>\n",
       "      <td>0.101757</td>\n",
       "      <td>0.485716</td>\n",
       "      <td>-0.959205</td>\n",
       "      <td>-0.201362</td>\n",
       "      <td>0.306136</td>\n",
       "      <td>-0.233086</td>\n",
       "      <td>0.614675</td>\n",
       "      <td>0.130512</td>\n",
       "      <td>-0.109402</td>\n",
       "      <td>1.650035</td>\n",
       "      <td>-0.616668</td>\n",
       "      <td>1.207558</td>\n",
       "      <td>0.079381</td>\n",
       "      <td>-1.866822</td>\n",
       "      <td>0.954838</td>\n",
       "      <td>1.295008</td>\n",
       "      <td>-0.491225</td>\n",
       "      <td>0.109172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.340456</td>\n",
       "      <td>0.124504</td>\n",
       "      <td>0.706386</td>\n",
       "      <td>-0.039325</td>\n",
       "      <td>-1.869652</td>\n",
       "      <td>-0.090968</td>\n",
       "      <td>0.572494</td>\n",
       "      <td>-1.036518</td>\n",
       "      <td>0.431760</td>\n",
       "      <td>-0.094413</td>\n",
       "      <td>-0.080917</td>\n",
       "      <td>2.288663</td>\n",
       "      <td>-0.692704</td>\n",
       "      <td>1.438392</td>\n",
       "      <td>0.551767</td>\n",
       "      <td>-2.188156</td>\n",
       "      <td>0.981590</td>\n",
       "      <td>1.238949</td>\n",
       "      <td>-0.646491</td>\n",
       "      <td>0.325857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>0.326294</td>\n",
       "      <td>-0.023210</td>\n",
       "      <td>0.230602</td>\n",
       "      <td>0.160822</td>\n",
       "      <td>-0.692147</td>\n",
       "      <td>-0.475622</td>\n",
       "      <td>0.472906</td>\n",
       "      <td>-0.318113</td>\n",
       "      <td>0.846760</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>0.154257</td>\n",
       "      <td>1.800183</td>\n",
       "      <td>-0.254384</td>\n",
       "      <td>1.268652</td>\n",
       "      <td>-0.368574</td>\n",
       "      <td>-1.756184</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>1.569076</td>\n",
       "      <td>-0.922587</td>\n",
       "      <td>0.317353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6735 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "2022  0.380136  0.013557  0.444868 -0.159154 -1.882184 -0.540239  0.408776   \n",
       "9873  0.289691 -0.109464 -0.062073  0.069794 -0.060432 -0.338151  0.501673   \n",
       "2542  0.051725  0.014099 -0.670242  0.301025  0.911384 -0.825443 -0.268050   \n",
       "2732  0.184398 -0.174997  1.742006 -0.606104 -2.578461 -0.553388  1.377012   \n",
       "8653  0.273693  0.029989 -0.293199  0.162781  0.058210 -0.401742 -0.079954   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5734  0.426053  0.128535  0.595150  0.171173 -1.627591 -0.138677  0.623442   \n",
       "5191  0.235136 -0.023087  0.553511 -0.039840 -1.806681 -0.424436  0.561687   \n",
       "5390  0.026033  0.291060  0.101757  0.485716 -0.959205 -0.201362  0.306136   \n",
       "860   0.340456  0.124504  0.706386 -0.039325 -1.869652 -0.090968  0.572494   \n",
       "7270  0.326294 -0.023210  0.230602  0.160822 -0.692147 -0.475622  0.472906   \n",
       "\n",
       "             7         8         9        10        11        12        13  \\\n",
       "2022 -1.003661  0.658224 -0.132428 -0.003633  2.374494 -0.924737  1.911677   \n",
       "9873  0.022923  1.027111 -0.157100  0.306545  0.721678  0.282060  1.033581   \n",
       "2542  0.684835  0.127059  0.184599  0.328975 -0.417977  0.437139  0.252209   \n",
       "2732 -1.053009  1.777836 -0.157670 -0.558999  3.678346 -0.997593  1.036072   \n",
       "8653  0.093336  0.364464 -0.062191  0.248690  0.318145 -0.248417  0.583351   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5734 -0.846837  0.867146  0.161239  0.045224  2.244308 -0.722979  1.328255   \n",
       "5191 -1.063671  1.194095 -0.208619 -0.022236  2.639043 -0.603684  1.461889   \n",
       "5390 -0.233086  0.614675  0.130512 -0.109402  1.650035 -0.616668  1.207558   \n",
       "860  -1.036518  0.431760 -0.094413 -0.080917  2.288663 -0.692704  1.438392   \n",
       "7270 -0.318113  0.846760  0.004811  0.154257  1.800183 -0.254384  1.268652   \n",
       "\n",
       "            14        15        16        17        18        19  \n",
       "2022  0.182614 -2.683055  1.372901  1.415666 -1.037116  0.627431  \n",
       "9873 -0.337916 -1.303151  0.790982  1.671680 -0.667830  0.188300  \n",
       "2542 -0.898743 -0.021114  0.432363  0.385303  0.062679  0.707053  \n",
       "2732  0.981599 -1.818053  0.708083  1.311199 -1.387904  0.121383  \n",
       "8653 -0.554918 -0.944436  0.633883  1.261529 -0.604498  0.177346  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "5734  0.217344 -1.890015  0.727113  1.181411 -0.963641  0.026678  \n",
       "5191  0.264556 -2.185811  1.075058  1.943642 -1.133654  0.504604  \n",
       "5390  0.079381 -1.866822  0.954838  1.295008 -0.491225  0.109172  \n",
       "860   0.551767 -2.188156  0.981590  1.238949 -0.646491  0.325857  \n",
       "7270 -0.368574 -1.756184  0.992500  1.569076 -0.922587  0.317353  \n",
       "\n",
       "[6735 rows x 20 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_txt_train_subcounts = count_vect.transform(x_txt_train.loc[train_subset.index])\n",
    "x_txt_test_subcounts = count_vect.transform(x_txt_test.loc[test_subset.index])\n",
    "\n",
    "audio_emb_train = train_subset.values\n",
    "audio_emb_test = test_subset.values\n",
    "\n",
    "x_mix_em_train = np.hstack((x_txt_train_subcounts.toarray(), audio_emb_train))\n",
    "x_mix_em_test = np.hstack((x_txt_test_subcounts.toarray(), audio_emb_test))\n",
    "\n",
    "y_num_train_sub = np.array(y)[train_subset.index]\n",
    "y_num_test_sub = np.array(y)[test_subset.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sent_train_sub = train_df['sentiment_int'][train_subset.index].values\n",
    "y_sent_test_sub = train_df['sentiment_int'][test_subset.index].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2763, 4: 1821, 1: 1376, 6: 1297, 3: 1023, 2: 711, 5: 706})\n"
     ]
    }
   ],
   "source": [
    "over = SMOTE(sampling_strategy=over_dicts[1], k_neighbors=10)\n",
    "under = RandomUnderSampler(sampling_strategy=under_dicts[0])\n",
    "x_new_train, y_new_train = over.fit_resample(x_mix_em_train, y_num_train_sub)\n",
    "x_new_train, y_new_train = under.fit_resample(x_new_train, y_new_train)\n",
    "\n",
    "print(Counter(y_new_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed:  1.2min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'penalty' : ['l1', 'l2'],\n",
    "    'class_weight': [ \"balanced\"],\n",
    "    'C' : [0.001, 0.01, 0.05, 0.1, 1, 1.5, 10],\n",
    "    'solver' : ['liblinear']}\n",
    "\n",
    "# Create grid search object\n",
    "logit = LogisticRegression(random_state=1)\n",
    "grid_cv = GridSearchCV(logit, param_grid = param_grid, cv = 5, verbose=1, n_jobs=2).fit(x_mix_em_train, y_num_train_sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.420623</td>\n",
       "      <td>0.011446</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.01, 'class_weight': 'balanced', 'penal...</td>\n",
       "      <td>0.493671</td>\n",
       "      <td>0.485480</td>\n",
       "      <td>0.491437</td>\n",
       "      <td>0.486225</td>\n",
       "      <td>0.476900</td>\n",
       "      <td>0.486743</td>\n",
       "      <td>0.005810</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.396929</td>\n",
       "      <td>0.020152</td>\n",
       "      <td>0.011497</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.05</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.05, 'class_weight': 'balanced', 'penal...</td>\n",
       "      <td>0.481757</td>\n",
       "      <td>0.486225</td>\n",
       "      <td>0.494415</td>\n",
       "      <td>0.495905</td>\n",
       "      <td>0.472429</td>\n",
       "      <td>0.486146</td>\n",
       "      <td>0.008614</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.373426</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>0.012251</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.01, 'class_weight': 'balanced', 'penal...</td>\n",
       "      <td>0.478779</td>\n",
       "      <td>0.478779</td>\n",
       "      <td>0.478779</td>\n",
       "      <td>0.477290</td>\n",
       "      <td>0.478390</td>\n",
       "      <td>0.478403</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.368820</td>\n",
       "      <td>0.004761</td>\n",
       "      <td>0.011669</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.001</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.001, 'class_weight': 'balanced', 'pena...</td>\n",
       "      <td>0.476545</td>\n",
       "      <td>0.475800</td>\n",
       "      <td>0.474311</td>\n",
       "      <td>0.466865</td>\n",
       "      <td>0.474665</td>\n",
       "      <td>0.473637</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.599049</td>\n",
       "      <td>0.115255</td>\n",
       "      <td>0.012418</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.05</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.05, 'class_weight': 'balanced', 'penal...</td>\n",
       "      <td>0.483246</td>\n",
       "      <td>0.465376</td>\n",
       "      <td>0.479523</td>\n",
       "      <td>0.481757</td>\n",
       "      <td>0.451565</td>\n",
       "      <td>0.472294</td>\n",
       "      <td>0.012160</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "3       0.420623      0.011446         0.011500        0.000323    0.01   \n",
       "4       0.396929      0.020152         0.011497        0.000603    0.05   \n",
       "2       0.373426      0.003378         0.012251        0.002064    0.01   \n",
       "1       0.368820      0.004761         0.011669        0.000686   0.001   \n",
       "5       0.599049      0.115255         0.012418        0.001011    0.05   \n",
       "\n",
       "  param_class_weight param_penalty param_solver  \\\n",
       "3           balanced            l2    liblinear   \n",
       "4           balanced            l1    liblinear   \n",
       "2           balanced            l1    liblinear   \n",
       "1           balanced            l2    liblinear   \n",
       "5           balanced            l2    liblinear   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "3  {'C': 0.01, 'class_weight': 'balanced', 'penal...           0.493671   \n",
       "4  {'C': 0.05, 'class_weight': 'balanced', 'penal...           0.481757   \n",
       "2  {'C': 0.01, 'class_weight': 'balanced', 'penal...           0.478779   \n",
       "1  {'C': 0.001, 'class_weight': 'balanced', 'pena...           0.476545   \n",
       "5  {'C': 0.05, 'class_weight': 'balanced', 'penal...           0.483246   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "3           0.485480           0.491437           0.486225           0.476900   \n",
       "4           0.486225           0.494415           0.495905           0.472429   \n",
       "2           0.478779           0.478779           0.477290           0.478390   \n",
       "1           0.475800           0.474311           0.466865           0.474665   \n",
       "5           0.465376           0.479523           0.481757           0.451565   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "3         0.486743        0.005810                1  \n",
       "4         0.486146        0.008614                2  \n",
       "2         0.478403        0.000577                3  \n",
       "1         0.473637        0.003479                4  \n",
       "5         0.472294        0.012160                5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_cv.cv_results_).sort_values(['rank_test_score'])\n",
    "display(results.head(5))\n",
    "grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.11      0.00      0.01       283\n",
      "     disgust       0.10      0.03      0.05        60\n",
      "        fear       0.04      0.02      0.03        51\n",
      "         joy       0.49      0.08      0.14       382\n",
      "     neutral       0.49      0.91      0.63      1058\n",
      "     sadness       0.29      0.12      0.17       147\n",
      "    surprise       0.49      0.19      0.27       304\n",
      "\n",
      "    accuracy                           0.47      2285\n",
      "   macro avg       0.29      0.19      0.19      2285\n",
      "weighted avg       0.41      0.47      0.37      2285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit = LogisticRegression(random_state=1, **grid_cv.best_params_)\n",
    "# logit.fit(x_new_train, y_new_train)\n",
    "logit.fit(x_mix_em_train, y_num_train_sub)\n",
    "y_predict = logit.predict(x_mix_em_test)\n",
    "\n",
    "print(classification_report(y_num_test_sub, y_predict, labels=labels_ordered, target_names=temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=2)]: Done  80 out of  80 | elapsed:   48.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.777507</td>\n",
       "      <td>0.052047</td>\n",
       "      <td>0.014830</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.15</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.15, 'class_weight': 'balanced', 'penal...</td>\n",
       "      <td>0.524944</td>\n",
       "      <td>0.522710</td>\n",
       "      <td>0.542815</td>\n",
       "      <td>0.542815</td>\n",
       "      <td>0.500745</td>\n",
       "      <td>0.526806</td>\n",
       "      <td>0.015569</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.824573</td>\n",
       "      <td>0.112009</td>\n",
       "      <td>0.016188</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>0.09</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.09, 'class_weight': 'balanced', 'penal...</td>\n",
       "      <td>0.530156</td>\n",
       "      <td>0.519732</td>\n",
       "      <td>0.534624</td>\n",
       "      <td>0.545793</td>\n",
       "      <td>0.502981</td>\n",
       "      <td>0.526657</td>\n",
       "      <td>0.014494</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.697143</td>\n",
       "      <td>0.027280</td>\n",
       "      <td>0.013988</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'penalt...</td>\n",
       "      <td>0.528667</td>\n",
       "      <td>0.517498</td>\n",
       "      <td>0.536113</td>\n",
       "      <td>0.548771</td>\n",
       "      <td>0.500745</td>\n",
       "      <td>0.526359</td>\n",
       "      <td>0.016355</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.824714</td>\n",
       "      <td>0.050353</td>\n",
       "      <td>0.016092</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.06</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.06, 'class_weight': 'balanced', 'penal...</td>\n",
       "      <td>0.528667</td>\n",
       "      <td>0.510797</td>\n",
       "      <td>0.532390</td>\n",
       "      <td>0.539836</td>\n",
       "      <td>0.499255</td>\n",
       "      <td>0.522189</td>\n",
       "      <td>0.014921</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.321064</td>\n",
       "      <td>0.392403</td>\n",
       "      <td>0.023663</td>\n",
       "      <td>0.008375</td>\n",
       "      <td>1.5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1.5, 'class_weight': 'balanced', 'penalt...</td>\n",
       "      <td>0.517498</td>\n",
       "      <td>0.526433</td>\n",
       "      <td>0.538347</td>\n",
       "      <td>0.521221</td>\n",
       "      <td>0.488077</td>\n",
       "      <td>0.518315</td>\n",
       "      <td>0.016677</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "11       0.777507      0.052047         0.014830        0.001822    0.15   \n",
       "7        0.824573      0.112009         0.016188        0.002244    0.09   \n",
       "9        0.697143      0.027280         0.013988        0.001231     0.1   \n",
       "5        0.824714      0.050353         0.016092        0.001253    0.06   \n",
       "12       2.321064      0.392403         0.023663        0.008375     1.5   \n",
       "\n",
       "   param_class_weight param_penalty param_solver  \\\n",
       "11           balanced            l2    liblinear   \n",
       "7            balanced            l2    liblinear   \n",
       "9            balanced            l2    liblinear   \n",
       "5            balanced            l2    liblinear   \n",
       "12           balanced            l1    liblinear   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "11  {'C': 0.15, 'class_weight': 'balanced', 'penal...           0.524944   \n",
       "7   {'C': 0.09, 'class_weight': 'balanced', 'penal...           0.530156   \n",
       "9   {'C': 0.1, 'class_weight': 'balanced', 'penalt...           0.528667   \n",
       "5   {'C': 0.06, 'class_weight': 'balanced', 'penal...           0.528667   \n",
       "12  {'C': 1.5, 'class_weight': 'balanced', 'penalt...           0.517498   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "11           0.522710           0.542815           0.542815   \n",
       "7            0.519732           0.534624           0.545793   \n",
       "9            0.517498           0.536113           0.548771   \n",
       "5            0.510797           0.532390           0.539836   \n",
       "12           0.526433           0.538347           0.521221   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "11           0.500745         0.526806        0.015569                1  \n",
       "7            0.502981         0.526657        0.014494                2  \n",
       "9            0.500745         0.526359        0.016355                3  \n",
       "5            0.499255         0.522189        0.014921                4  \n",
       "12           0.488077         0.518315        0.016677                5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'penalty' : ['l1', 'l2'],\n",
    "    'class_weight': [ \"balanced\"],\n",
    "    'C' : [0.001, 0.01, 0.06, 0.09, 0.1, 0.15, 1.5, 10],\n",
    "    'solver' : ['liblinear']}\n",
    "\n",
    "# Create grid search object\n",
    "logit = LogisticRegression(random_state=1)\n",
    "grid_cv_sent = GridSearchCV(logit, param_grid = param_grid, cv = 5, verbose=1, n_jobs=2).fit(x_mix_em_train, y_sent_train_sub)\n",
    "\n",
    "results = pd.DataFrame(grid_cv_sent.cv_results_).sort_values(['rank_test_score'])\n",
    "display(results.head(5))\n",
    "grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.47      0.37      0.42       711\n",
      "     neutral       0.55      0.70      0.62      1058\n",
      "    positive       0.43      0.32      0.36       516\n",
      "\n",
      "    accuracy                           0.51      2285\n",
      "   macro avg       0.48      0.46      0.47      2285\n",
      "weighted avg       0.50      0.51      0.50      2285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logit_sent = LogisticRegression(random_state=1, **grid_cv_sent.best_params_)\n",
    "# logit.fit(x_new_train, y_new_train)\n",
    "logit_sent.fit(x_mix_em_train, y_sent_train_sub)\n",
    "y_predict_sent = logit_sent.predict(x_mix_em_test)\n",
    "\n",
    "print(classification_report(y_sent_test_sub, y_predict_sent, target_names=sentiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
